# TextLoom å¼€æºè§†é¢‘å¼•æ“å®æ–½è·¯çº¿å›¾

> **å®Œå…¨å¼€æºæ–¹æ¡ˆ** - å››é˜¶æ®µæ¸è¿›å¼å®æ–½è®¡åˆ’
>
> ä½œè€…: Claude + ç”¨æˆ·
> åˆ›å»º: 2025-11-17
> çŠ¶æ€: å‡†å¤‡å¯åŠ¨

---

## ğŸ¯ æ€»ä½“ç›®æ ‡

ä½¿ç”¨å¼€æºæŠ€æœ¯æ ˆæ›¿ä»£å•†ä¸šè§†é¢‘åˆæˆ APIï¼Œå®ç°ï¼š
- âœ… **100% å¼€æº** - æ— å•†ä¸š API ä¾èµ–
- âœ… **æˆæœ¬é™ä½ 90%+** - ä»…éœ€ GPU æœåŠ¡å™¨æˆæœ¬
- âœ… **å®Œå…¨å¯æ§** - æ•°æ®å’ŒæŠ€æœ¯è‡ªä¸»

---

## ğŸ“Š å››é˜¶æ®µå®æ–½è®¡åˆ’

### é˜¶æ®µ 1ï¸âƒ£ï¼šæµ‹è¯•éªŒè¯ Editly åŸºç¡€åŠŸèƒ½

**æ—¶é—´**: 3-5 å¤©
**ç›®æ ‡**: éªŒè¯ Editly èƒ½å¦æ»¡è¶³åŸºç¡€è§†é¢‘åˆæˆéœ€æ±‚
**ä¼˜å…ˆçº§**: ğŸ”´ P0 - å¿…é¡»å®Œæˆ

#### 1.1 å®‰è£…å’Œé…ç½®

**ä»»åŠ¡æ¸…å•**:
- [ ] å®‰è£… Node.js (v14+ LTS)
- [ ] å®‰è£… FFmpeg
- [ ] å®‰è£… Editly ä¾èµ–
  ```bash
  cd editly
  npm install
  npm run build
  ```
- [ ] éªŒè¯ Editly CLI å¯ç”¨
  ```bash
  node dist/cli.js --version
  ```

**éªŒæ”¶æ ‡å‡†**:
- Editly å‘½ä»¤èƒ½æ­£å¸¸æ‰§è¡Œ
- FFmpeg ç‰ˆæœ¬ >= 4.0

#### 1.2 åŸºç¡€åŠŸèƒ½æµ‹è¯•

**æµ‹è¯•åœºæ™¯**:

##### æµ‹è¯• 1: å›¾ç‰‡å¹»ç¯ç‰‡
```json5
// test_slideshow.json5
{
  outPath: "output/test1_slideshow.mp4",
  width: 1080,
  height: 1920,
  fps: 30,
  clips: [
    {
      duration: 3,
      layers: [
        { type: "fill-color", color: "#0066cc" },
        {
          type: "title",
          text: "æµ‹è¯•æ ‡é¢˜",
          textColor: "#ffffff"
        }
      ]
    },
    {
      duration: 3,
      layers: [
        {
          type: "image",
          path: "workspace/materials/images/sample1.jpg"
        }
      ]
    }
  ]
}
```

è¿è¡Œ:
```bash
node editly/dist/cli.js test_slideshow.json5
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… è§†é¢‘ç”ŸæˆæˆåŠŸ
- âœ… åˆ†è¾¨ç‡æ­£ç¡® (1080x1920)
- âœ… å¸§ç‡æ­£ç¡® (30fps)
- âœ… æ ‡é¢˜æ¸…æ™°å¯è¯»

##### æµ‹è¯• 2: è§†é¢‘æ‹¼æ¥ + è½¬åœº
```json5
// test_transitions.json5
{
  outPath: "output/test2_transitions.mp4",
  clips: [
    {
      duration: 2,
      transition: { name: "fade", duration: 0.5 },
      layers: [
        { type: "video", path: "test_video1.mp4" }
      ]
    },
    {
      duration: 2,
      transition: { name: "crosswarp", duration: 0.5 },
      layers: [
        { type: "video", path: "test_video2.mp4" }
      ]
    }
  ]
}
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… è½¬åœºæ•ˆæœæµç•…
- âœ… æ— é»‘å±æˆ–å¡é¡¿
- âœ… æ—¶é•¿å‡†ç¡®

##### æµ‹è¯• 3: è‡ªå®šä¹‰å­—å¹• (Fabric.js)
```json5
// test_subtitle.json5
{
  outPath: "output/test3_subtitle.mp4",
  clips: [
    {
      duration: 5,
      layers: [
        { type: "fill-color", color: "#000000" },
        {
          type: "fabric",
          func: `
            ({ fabric, canvas, params }) => {
              const text = new fabric.Text('è‡ªå®šä¹‰å­—å¹•æµ‹è¯•', {
                left: 100,
                top: 1700,
                fontSize: 60,
                fill: '#ffffff',
                stroke: '#000000',
                strokeWidth: 2
              });
              canvas.add(text);
            }
          `
        }
      ]
    }
  ]
}
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… å­—å¹•ä½ç½®ç²¾ç¡®
- âœ… å­—ä½“å¤§å°æ­£ç¡®
- âœ… æè¾¹æ•ˆæœæ¸…æ™°

##### æµ‹è¯• 4: éŸ³é¢‘æ··åˆ
```json5
// test_audio.json5
{
  outPath: "output/test4_audio.mp4",
  audioFilePath: "background_music.mp3",
  clips: [
    {
      duration: 5,
      layers: [
        { type: "video", path: "test_video.mp4" }
      ]
    }
  ],
  keepSourceAudio: true,
  clipsAudioVolume: 0.7
}
```

**éªŒæ”¶æ ‡å‡†**:
- âœ… èƒŒæ™¯éŸ³ä¹æ­£å¸¸æ’­æ”¾
- âœ… åŸè§†é¢‘éŸ³é¢‘ä¿ç•™
- âœ… éŸ³é‡å¹³è¡¡åˆç†

#### 1.3 æ€§èƒ½æµ‹è¯•

**æµ‹è¯•æŒ‡æ ‡**:

| è§†é¢‘è§„æ ¼ | æ—¶é•¿ | é¢„æœŸç”Ÿæˆæ—¶é—´ | å®é™…æ—¶é—´ | é€šè¿‡ |
|---------|------|------------|---------|------|
| 1080x1920 @ 30fps | 30s | < 2 åˆ†é’Ÿ | _______ | â˜ |
| 1080x1920 @ 30fps | 60s | < 4 åˆ†é’Ÿ | _______ | â˜ |
| 720x1280 @ 30fps | 30s | < 1 åˆ†é’Ÿ | _______ | â˜ |

**ç¡¬ä»¶è¦æ±‚**:
- CPU: 4 æ ¸ä»¥ä¸Š
- å†…å­˜: 8GB+
- ç£ç›˜: 10GB+ å¯ç”¨ç©ºé—´

#### 1.4 é˜¶æ®µ 1 äº¤ä»˜ç‰©

- [ ] Editly åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š (Markdown)
- [ ] 5 ä¸ªæµ‹è¯•è§†é¢‘æ ·æœ¬
- [ ] æ€§èƒ½åŸºå‡†æ•°æ®
- [ ] é—®é¢˜å’Œé™åˆ¶æ¸…å•

**Go/No-Go å†³ç­–**:
- âœ… **Go**: æ‰€æœ‰åŸºç¡€æµ‹è¯•é€šè¿‡ï¼Œæ€§èƒ½æ»¡è¶³éœ€æ±‚
- âŒ **No-Go**: å…³é”®åŠŸèƒ½ç¼ºå¤±æˆ–æ€§èƒ½ä¸è¾¾æ ‡ â†’ é‡æ–°è¯„ä¼°æ–¹æ¡ˆ

---

### é˜¶æ®µ 2ï¸âƒ£ï¼šå¼€æº TTS é›†æˆ

**æ—¶é—´**: 1-2 å‘¨
**ç›®æ ‡**: é›†æˆå¼€æº TTSï¼Œå®ç°æ–‡æœ¬è½¬è¯­éŸ³
**ä¼˜å…ˆçº§**: ğŸŸ¡ P1

#### 2.1 TTS æŠ€æœ¯é€‰å‹

##### æ–¹æ¡ˆ A: GPT-SoVITS (æ¨è â­â­â­â­â­)

**é¡¹ç›®åœ°å€**: https://github.com/RVC-Boss/GPT-SoVITS

**ä¼˜ç‚¹**:
- âœ… **ä¸­æ–‡æ•ˆæœæä½³** - ä¸“ä¸ºä¸­æ–‡ä¼˜åŒ–
- âœ… **å£°éŸ³å…‹éš†** - 5 ç§’æ ·æœ¬å³å¯å…‹éš†å£°éŸ³
- âœ… **æƒ…æ„Ÿä¸°å¯Œ** - æ”¯æŒå¤šç§æƒ…æ„Ÿè¡¨è¾¾
- âœ… **æ´»è·ƒç»´æŠ¤** - ç¤¾åŒºæ´»è·ƒï¼Œæ›´æ–°é¢‘ç¹
- âœ… **æœ¬åœ°éƒ¨ç½²** - å®Œå…¨ç¦»çº¿è¿è¡Œ

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦ GPU (æ¨è NVIDIA RTX 3060+)
- âš ï¸ æ¨¡å‹è¾ƒå¤§ (çº¦ 2GB)
- âš ï¸ æ¨ç†é€Ÿåº¦ä¸­ç­‰ (1s éŸ³é¢‘çº¦éœ€ 2-3s)

**ç¡¬ä»¶è¦æ±‚**:
```
GPU: NVIDIA RTX 3060 (12GB VRAM) æˆ–æ›´é«˜
CPU: 8 æ ¸+
å†…å­˜: 16GB+
ç£ç›˜: 10GB+ (æ¨¡å‹ + ç¼“å­˜)
```

**å®‰è£…æ­¥éª¤**:
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/RVC-Boss/GPT-SoVITS.git
cd GPT-SoVITS

# 2. åˆ›å»º Python ç¯å¢ƒ
conda create -n gptsovits python=3.10
conda activate gptsovits

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
python download_models.py

# 5. å¯åŠ¨ API æœåŠ¡
python api.py
```

**API ç¤ºä¾‹**:
```python
import requests

response = requests.post(
    "http://localhost:9880/tts",
    json={
        "text": "è¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³",
        "text_language": "zh",
        "ref_audio_path": "reference.wav",  # å‚è€ƒéŸ³é¢‘ï¼ˆå£°éŸ³å…‹éš†ï¼‰
        "prompt_text": "å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬",
        "prompt_language": "zh",
        "top_k": 5,
        "top_p": 1,
        "temperature": 1
    }
)

with open("output.wav", "wb") as f:
    f.write(response.content)
```

##### æ–¹æ¡ˆ B: Piper TTS (å¤‡é€‰ â­â­â­â­)

**é¡¹ç›®åœ°å€**: https://github.com/rhasspy/piper

**ä¼˜ç‚¹**:
- âœ… **æå¿«é€Ÿåº¦** - å®æ—¶ç‡ > 1 (æ¯”å®æ—¶å¿«)
- âœ… **ä½èµ„æº** - CPU å³å¯è¿è¡Œ
- âœ… **å¤šè¯­è¨€** - 40+ è¯­è¨€
- âœ… **æ¨¡å‹å°** - 10-50MB

**ç¼ºç‚¹**:
- âš ï¸ ä¸­æ–‡å£°éŸ³é€‰æ‹©è¾ƒå°‘
- âš ï¸ æƒ…æ„Ÿè¡¨è¾¾ä¸€èˆ¬
- âš ï¸ æ— å£°éŸ³å…‹éš†åŠŸèƒ½

**é€‚ç”¨åœºæ™¯**: å¯¹é€Ÿåº¦è¦æ±‚é«˜ï¼Œå¯¹å£°éŸ³è´¨é‡è¦æ±‚ä¸€èˆ¬

##### æ–¹æ¡ˆ C: Coqui TTS (å¤‡é€‰ â­â­â­)

**é¡¹ç›®åœ°å€**: https://github.com/coqui-ai/TTS

**ä¼˜ç‚¹**:
- âœ… å¤šæ¨¡å‹æ”¯æŒ (Tacotron2, VITS ç­‰)
- âœ… å£°éŸ³å…‹éš†
- âœ… æƒ…æ„Ÿæ§åˆ¶

**ç¼ºç‚¹**:
- âš ï¸ é¡¹ç›®å·²åœæ­¢ç»´æŠ¤ (2023å¹´)
- âš ï¸ ä¸­æ–‡æ”¯æŒä¸€èˆ¬
- âš ï¸ å®‰è£…å¤æ‚

**æ¨èæŒ‡æ•°**: ä½

#### 2.2 GPT-SoVITS é›†æˆæ–¹æ¡ˆï¼ˆæ¨èï¼‰

##### 2.2.1 åˆ›å»º TTS æ’ä»¶æ¥å£

```python
# textloom/services/tts/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional

class TTSEngine(ABC):
    """TTS å¼•æ“æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def synthesize(
        self,
        text: str,
        voice_config: Dict[str, Any],
        output_path: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        åˆæˆè¯­éŸ³

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_config: å£°éŸ³é…ç½®ï¼ˆå£°éŸ³IDã€å‚è€ƒéŸ³é¢‘ç­‰ï¼‰
            output_path: è¾“å‡ºéŸ³é¢‘è·¯å¾„

        Returns:
            {
                "success": bool,
                "audio_path": str,
                "duration": float,
                "error": str (å¯é€‰)
            }
        """
        pass

    @abstractmethod
    def get_available_voices(self) -> list:
        """è·å–å¯ç”¨çš„å£°éŸ³åˆ—è¡¨"""
        pass
```

##### 2.2.2 å®ç° GPT-SoVITS å¼•æ“

```python
# textloom/services/tts/gptsovits_engine.py
import requests
import time
from pathlib import Path
from typing import Dict, Any

from .base import TTSEngine
from utils.sync_logging import get_logger

logger = get_logger(__name__)


class GPTSoVITSEngine(TTSEngine):
    """GPT-SoVITS TTS å¼•æ“"""

    def __init__(
        self,
        api_url: str = "http://localhost:9880",
        reference_audio_dir: str = "workspace/tts/references"
    ):
        self.api_url = api_url
        self.reference_audio_dir = Path(reference_audio_dir)
        self.reference_audio_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"GPT-SoVITS å¼•æ“åˆå§‹åŒ–: {api_url}")

    def synthesize(
        self,
        text: str,
        voice_config: Dict[str, Any],
        output_path: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ GPT-SoVITS åˆæˆè¯­éŸ³

        voice_config æ ¼å¼:
        {
            "voice_id": "female_1",
            "ref_audio_path": "workspace/tts/references/female_1.wav",
            "ref_text": "å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹",
            "language": "zh",
            "top_k": 5,
            "top_p": 1.0,
            "temperature": 1.0
        }
        """
        try:
            logger.info(f"å¼€å§‹åˆæˆè¯­éŸ³: {text[:50]}...")

            # æ„å»ºè¯·æ±‚
            payload = {
                "text": text,
                "text_language": voice_config.get("language", "zh"),
                "ref_audio_path": voice_config.get("ref_audio_path"),
                "prompt_text": voice_config.get("ref_text", ""),
                "prompt_language": voice_config.get("language", "zh"),
                "top_k": voice_config.get("top_k", 5),
                "top_p": voice_config.get("top_p", 1.0),
                "temperature": voice_config.get("temperature", 1.0),
            }

            # è°ƒç”¨ API
            start_time = time.time()
            response = requests.post(
                f"{self.api_url}/tts",
                json=payload,
                timeout=60
            )

            if response.status_code != 200:
                raise RuntimeError(f"TTS API è°ƒç”¨å¤±è´¥: {response.status_code}")

            # ä¿å­˜éŸ³é¢‘
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "wb") as f:
                f.write(response.content)

            # è·å–éŸ³é¢‘æ—¶é•¿
            duration = self._get_audio_duration(output_path)
            elapsed = time.time() - start_time

            logger.info(
                f"âœ… è¯­éŸ³åˆæˆæˆåŠŸ: {output_path}, "
                f"æ—¶é•¿: {duration}s, è€—æ—¶: {elapsed:.2f}s"
            )

            return {
                "success": True,
                "audio_path": output_path,
                "duration": duration,
                "synthesis_time": elapsed
            }

        except Exception as e:
            logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def get_available_voices(self) -> list:
        """è·å–å¯ç”¨çš„å£°éŸ³åˆ—è¡¨"""
        # æ‰«æå‚è€ƒéŸ³é¢‘ç›®å½•
        voices = []
        for ref_audio in self.reference_audio_dir.glob("*.wav"):
            voice_id = ref_audio.stem
            voices.append({
                "voice_id": voice_id,
                "ref_audio_path": str(ref_audio),
                "language": "zh"  # é»˜è®¤ä¸­æ–‡
            })
        return voices

    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        import subprocess
        cmd = [
            "ffprobe",
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        return float(result.stdout.strip())
```

##### 2.2.3 é…ç½®ç®¡ç†

åœ¨ `.env` ä¸­æ·»åŠ :
```bash
# TTS é…ç½®
TTS_ENGINE=gptsovits  # æˆ– piper, coqui
TTS_API_URL=http://localhost:9880
TTS_REFERENCE_AUDIO_DIR=workspace/tts/references

# GPT-SoVITS é…ç½®
GPTSOVITS_TOP_K=5
GPTSOVITS_TOP_P=1.0
GPTSOVITS_TEMPERATURE=1.0
```

#### 2.3 å£°éŸ³åº“ç®¡ç†

##### 2.3.1 åˆ›å»ºå£°éŸ³åº“

```bash
# ç›®å½•ç»“æ„
workspace/tts/references/
â”œâ”€â”€ male_1.wav           # ç”·å£° 1ï¼ˆå‚è€ƒéŸ³é¢‘ï¼‰
â”œâ”€â”€ male_1.txt           # ç”·å£° 1 å‚è€ƒæ–‡æœ¬
â”œâ”€â”€ female_1.wav         # å¥³å£° 1
â”œâ”€â”€ female_1.txt
â”œâ”€â”€ child_1.wav          # å„¿ç«¥å£°
â”œâ”€â”€ child_1.txt
â””â”€â”€ ...
```

##### 2.3.2 å£°éŸ³é…ç½®

```python
# textloom/config/voices.py
VOICE_LIBRARY = {
    "male_1": {
        "name": "ç”·å£°-æˆç†Ÿç¨³é‡",
        "ref_audio_path": "workspace/tts/references/male_1.wav",
        "ref_text": "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ã€‚",
        "language": "zh",
        "description": "é€‚åˆæ–°é—»ã€æ•™ç¨‹ç±»è§†é¢‘"
    },
    "female_1": {
        "name": "å¥³å£°-æ¸©æŸ”ç”œç¾",
        "ref_audio_path": "workspace/tts/references/female_1.wav",
        "ref_text": "ä»Šå¤©ç»™å¤§å®¶åˆ†äº«ä¸€ä¸ªæœ‰è¶£çš„è¯é¢˜ã€‚",
        "language": "zh",
        "description": "é€‚åˆç”Ÿæ´»ã€å¨±ä¹ç±»è§†é¢‘"
    }
}
```

#### 2.4 é›†æˆåˆ° Editly

```python
# textloom/services/editly_video_engine.py (æ›´æ–°)

class EditlyVideoEngine(VideoEngine):

    def __init__(self, tts_engine: Optional[TTSEngine] = None):
        self.tts_engine = tts_engine or self._create_default_tts_engine()
        # ...

    def _create_default_tts_engine(self):
        """åˆ›å»ºé»˜è®¤ TTS å¼•æ“"""
        from services.tts.gptsovits_engine import GPTSoVITSEngine
        return GPTSoVITSEngine()

    def generate_video(self, script_data, media_files, output_path, ...):
        # 1. ç”Ÿæˆ TTS éŸ³é¢‘
        audio_files = self._generate_audio_from_scenes(script_data["scenes"])

        # 2. è½¬æ¢ä¸º Editly é…ç½®ï¼ˆæ·»åŠ éŸ³é¢‘ï¼‰
        editly_config = self._convert_to_editly_config(
            script_data, media_files, output_path, audio_files
        )

        # 3. æ‰§è¡Œ Editly
        # ...

    def _generate_audio_from_scenes(self, scenes):
        """ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆ TTS éŸ³é¢‘"""
        audio_files = []

        for idx, scene in enumerate(scenes):
            narration = scene.get("narration", "").strip()
            if not narration:
                continue

            # ç”ŸæˆéŸ³é¢‘
            output_path = f"workspace/tts/output/scene_{idx+1}.wav"
            result = self.tts_engine.synthesize(
                text=narration,
                voice_config={
                    "voice_id": scene.get("voice_id", "female_1"),
                    "ref_audio_path": "workspace/tts/references/female_1.wav",
                    "ref_text": "å‚è€ƒæ–‡æœ¬",
                    "language": "zh"
                },
                output_path=output_path
            )

            if result["success"]:
                audio_files.append({
                    "scene_id": scene.get("scene_id"),
                    "audio_path": result["audio_path"],
                    "duration": result["duration"]
                })

        return audio_files
```

#### 2.5 é˜¶æ®µ 2 æµ‹è¯•

**æµ‹è¯•åœºæ™¯**:

##### æµ‹è¯• 1: å•å¥ TTS
```python
from services.tts.gptsovits_engine import GPTSoVITSEngine

engine = GPTSoVITSEngine()
result = engine.synthesize(
    text="æ¬¢è¿æ¥åˆ°TextLoomï¼Œè¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½è§†é¢‘ç”Ÿæˆç³»ç»Ÿã€‚",
    voice_config={
        "voice_id": "female_1",
        "ref_audio_path": "workspace/tts/references/female_1.wav",
        "ref_text": "å‚è€ƒæ–‡æœ¬",
        "language": "zh"
    },
    output_path="test_tts.wav"
)
print(result)
```

##### æµ‹è¯• 2: å¤šåœºæ™¯ TTS + Editly
```python
script_data = {
    "scenes": [
        {
            "scene_id": 1,
            "narration": "å¤§å®¶å¥½ï¼Œä»Šå¤©ç»™å¤§å®¶ä»‹ç»ä¸€ä¸ªæ–°äº§å“ã€‚",
            "voice_id": "female_1",
            "duration": 5.0
        },
        {
            "scene_id": 2,
            "narration": "è¿™ä¸ªäº§å“æœ‰ä¸‰ä¸ªä¸»è¦ç‰¹ç‚¹ã€‚",
            "voice_id": "female_1",
            "duration": 4.0
        }
    ]
}

engine = EditlyVideoEngine()
result = engine.generate_video(
    script_data=script_data,
    media_files=[],
    output_path="test_tts_video.mp4"
)
```

#### 2.6 é˜¶æ®µ 2 äº¤ä»˜ç‰©

- [ ] GPT-SoVITS éƒ¨ç½²æ–‡æ¡£
- [ ] TTS æ’ä»¶ä»£ç 
- [ ] å£°éŸ³åº“ï¼ˆè‡³å°‘ 3 ä¸ªå£°éŸ³ï¼‰
- [ ] é›†æˆæµ‹è¯•è§†é¢‘ï¼ˆ3 ä¸ªåœºæ™¯ï¼‰
- [ ] æ€§èƒ½æµ‹è¯•æŠ¥å‘Šï¼ˆTTS é€Ÿåº¦ï¼‰

---

### é˜¶æ®µ 3ï¸âƒ£ï¼šTextLoom é€‚é… Editly

**æ—¶é—´**: 2-3 å‘¨
**ç›®æ ‡**: å°† TextLoom å®Œå…¨åˆ‡æ¢åˆ° Editly å¼•æ“
**ä¼˜å…ˆçº§**: ğŸŸ¡ P1

#### 3.1 æ¶æ„è°ƒæ•´

##### 3.1.1 åŒå¼•æ“æ¶æ„ï¼ˆè¿‡æ¸¡æœŸï¼‰

```python
# textloom/services/video_engine_factory.py

from enum import Enum
from typing import Optional

class VideoEngineType(Enum):
    EDITLY = "editly"
    VIDEO_MERGE = "video_merge"  # å•†ä¸š API (å¤‡ä»½)

class VideoEngineFactory:
    """è§†é¢‘å¼•æ“å·¥å‚"""

    @staticmethod
    def create(
        engine_type: VideoEngineType,
        **kwargs
    ):
        if engine_type == VideoEngineType.EDITLY:
            from services.editly_video_engine import EditlyVideoEngine
            return EditlyVideoEngine(**kwargs)
        elif engine_type == VideoEngineType.VIDEO_MERGE:
            from services.sync_video_generator import SyncVideoGenerator
            return SyncVideoGenerator()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¼•æ“ç±»å‹: {engine_type}")

# ä½¿ç”¨
engine = VideoEngineFactory.create(
    VideoEngineType.EDITLY,
    tts_engine=tts_engine
)
```

##### 3.1.2 æ™ºèƒ½è·¯ç”±

```python
# textloom/services/video_engine_router.py

def select_video_engine(script_data: Dict) -> VideoEngineType:
    """
    æ™ºèƒ½é€‰æ‹©è§†é¢‘å¼•æ“

    è§„åˆ™:
    1. å¦‚æœæœ‰æ•°å­—äºº â†’ VIDEO_MERGE (é˜¶æ®µ 4 å‰)
    2. å¦‚æœæ²¡æœ‰ TTS æ”¯æŒ â†’ VIDEO_MERGE
    3. å…¶ä»– â†’ EDITLY
    """
    # æ£€æŸ¥æ•°å­—äºº
    has_digital_human = any(
        c.get("category") == 2
        for scene in script_data.get("scenes", [])
        for c in scene.get("components", [])
    )

    if has_digital_human:
        logger.info("æ£€æµ‹åˆ°æ•°å­—äººï¼Œä½¿ç”¨ VIDEO_MERGE å¼•æ“")
        return VideoEngineType.VIDEO_MERGE

    # æ£€æŸ¥ TTS
    has_tts = any(
        scene.get("narration", "").strip()
        for scene in script_data.get("scenes", [])
    )

    if has_tts and not settings.TTS_ENGINE:
        logger.warning("éœ€è¦ TTS ä½†æœªé…ç½®ï¼Œå›é€€åˆ° VIDEO_MERGE")
        return VideoEngineType.VIDEO_MERGE

    logger.info("ä½¿ç”¨ EDITLY å¼•æ“")
    return VideoEngineType.EDITLY
```

#### 3.2 é…ç½®è½¬æ¢ä¼˜åŒ–

##### 3.2.1 å¢å¼ºé…ç½®è½¬æ¢å™¨

```python
# textloom/services/editly_config_converter.py

class EditlyConfigConverter:
    """TextLoom â†’ Editly é…ç½®è½¬æ¢å™¨"""

    def convert(
        self,
        script_data: Dict,
        media_files: List[Dict],
        audio_files: List[Dict],
        output_path: str
    ) -> Dict:
        """å®Œæ•´é…ç½®è½¬æ¢"""

        editly_config = {
            "outPath": output_path,
            "width": settings.VIDEO_DEFAULT_WIDTH,
            "height": settings.VIDEO_DEFAULT_HEIGHT,
            "fps": 30,
            "clips": [],
            "audioTracks": []
        }

        # è½¬æ¢åœºæ™¯
        for idx, scene in enumerate(script_data.get("scenes", [])):
            clip = self._convert_scene(
                scene, media_files, audio_files, idx
            )
            editly_config["clips"].append(clip)

        # æ·»åŠ èƒŒæ™¯éŸ³ä¹
        if script_data.get("background_music"):
            editly_config["audioFilePath"] = script_data["background_music"]
            editly_config["loopAudio"] = True

        return editly_config

    def _convert_scene(self, scene, media_files, audio_files, idx):
        """è½¬æ¢å•ä¸ªåœºæ™¯"""
        # è¯¦ç»†å®ç°...
```

#### 3.3 Celery ä»»åŠ¡é€‚é…

```python
# textloom/tasks/video_generation_tasks.py (æ›´æ–°)

from services.video_engine_factory import VideoEngineFactory
from services.video_engine_router import select_video_engine

@celery_app.task(bind=True)
def generate_video_task(
    self,
    script_data: Dict,
    media_files: List[Dict],
    task_id: str,
    **kwargs
):
    """è§†é¢‘ç”Ÿæˆä»»åŠ¡ï¼ˆæ”¯æŒåŒå¼•æ“ï¼‰"""

    try:
        # 1. é€‰æ‹©å¼•æ“
        engine_type = select_video_engine(script_data)

        # 2. åˆ›å»ºå¼•æ“
        engine = VideoEngineFactory.create(engine_type)

        # 3. ç”Ÿæˆè§†é¢‘
        result = engine.generate_video(
            script_data=script_data,
            media_files=media_files,
            output_path=f"workspace/output/{task_id}.mp4",
            progress_callback=lambda p: self.update_state(
                state='PROGRESS',
                meta={'progress': p}
            )
        )

        return result

    except Exception as e:
        logger.error(f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")
        raise
```

#### 3.4 é˜¶æ®µ 3 æµ‹è¯•

**å®Œæ•´ç«¯åˆ°ç«¯æµ‹è¯•**:

```python
# tests/e2e/test_full_pipeline.py

def test_full_video_generation():
    """æµ‹è¯•å®Œæ•´çš„è§†é¢‘ç”Ÿæˆæµç¨‹"""

    # å‡†å¤‡æ•°æ®
    script_data = {
        "title": "æµ‹è¯•è§†é¢‘",
        "scenes": [
            {
                "scene_id": 1,
                "narration": "è¿™æ˜¯ç¬¬ä¸€ä¸ªåœºæ™¯",
                "material_id": "img_001",
                "voice_id": "female_1"
            },
            {
                "scene_id": 2,
                "narration": "è¿™æ˜¯ç¬¬äºŒä¸ªåœºæ™¯",
                "material_id": "img_002",
                "voice_id": "female_1"
            }
        ]
    }

    media_files = [
        {"id": "img_001", "file_url": "test1.jpg"},
        {"id": "img_002", "file_url": "test2.jpg"}
    ]

    # æ‰§è¡Œç”Ÿæˆ
    task = generate_video_task.delay(script_data, media_files, "test_task")
    result = task.get(timeout=300)

    # éªŒè¯
    assert result["success"] == True
    assert Path(result["video_path"]).exists()
```

#### 3.5 é˜¶æ®µ 3 äº¤ä»˜ç‰©

- [ ] åŒå¼•æ“æ¶æ„ä»£ç 
- [ ] é…ç½®è½¬æ¢å™¨
- [ ] Celery ä»»åŠ¡é€‚é…
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•å¥—ä»¶
- [ ] è¿ç§»æ–‡æ¡£
- [ ] æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

---

### é˜¶æ®µ 4ï¸âƒ£ï¼šæ•°å­—äººé›†æˆ

**æ—¶é—´**: 3-4 å‘¨
**ç›®æ ‡**: é›†æˆæ•°å­—äººåŠŸèƒ½ï¼Œå®ç°å®Œæ•´è§†é¢‘ç”Ÿæˆ
**ä¼˜å…ˆçº§**: ğŸŸ¢ P2

#### 4.1 æ•°å­—äººæŠ€æœ¯é€‰å‹

##### æ–¹æ¡ˆ A: HeyGen API (å•†ä¸šæ–¹æ¡ˆ)

**æ³¨æ„**: HeyGen æ˜¯å•†ä¸š APIï¼Œä¸æ˜¯å¼€æºçš„ã€‚

**ä»·æ ¼**: çº¦ $0.10/ç§’è§†é¢‘
**ä¼˜ç‚¹**:
- âœ… è´¨é‡æœ€é«˜
- âœ… ç¨³å®šå¯é 
- âœ… API ç®€å•

**ç¼ºç‚¹**:
- âŒ ä»˜è´¹æœåŠ¡
- âŒ æ•°æ®ä¸Šä¼ å¤–éƒ¨

**å»ºè®®**: å¦‚æœé¢„ç®—å…è®¸ï¼Œå¯ä½œä¸ºé¦–é€‰ã€‚

##### æ–¹æ¡ˆ B: SadTalker (å¼€æº â­â­â­â­)

**é¡¹ç›®åœ°å€**: https://github.com/OpenTalker/SadTalker

**ä¼˜ç‚¹**:
- âœ… å®Œå…¨å¼€æº
- âœ… æ•ˆæœè¾ƒå¥½
- âœ… æœ¬åœ°éƒ¨ç½²

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦ GPU (RTX 3090+)
- âš ï¸ ç”Ÿæˆé€Ÿåº¦æ…¢ (1min è§†é¢‘çº¦éœ€ 5-10min)
- âš ï¸ è´¨é‡ä¸å¦‚å•†ä¸šæ–¹æ¡ˆ

**ç¡¬ä»¶è¦æ±‚**:
```
GPU: NVIDIA RTX 3090 (24GB VRAM) æˆ–æ›´é«˜
CPU: 16 æ ¸+
å†…å­˜: 32GB+
```

##### æ–¹æ¡ˆ C: Wav2Lip (å¼€æº â­â­â­)

**é¡¹ç›®åœ°å€**: https://github.com/Rudrabha/Wav2Lip

**ä¼˜ç‚¹**:
- âœ… è½»é‡çº§
- âœ… é€Ÿåº¦è¾ƒå¿«
- âœ… å”‡å½¢åŒæ­¥å‡†ç¡®

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦é¢„å…ˆå½•åˆ¶è§†é¢‘
- âš ï¸ è¡¨æƒ…å•ä¸€
- âš ï¸ åˆ†è¾¨ç‡æœ‰é™

**æ¨èåœºæ™¯**: å¯¹è´¨é‡è¦æ±‚ä¸é«˜ï¼Œè¿½æ±‚é€Ÿåº¦

#### 4.2 æ¨èæ–¹æ¡ˆ: SadTalker

##### 4.2.1 éƒ¨ç½² SadTalker

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

# 2. å®‰è£…ä¾èµ–
conda create -n sadtalker python=3.8
conda activate sadtalker
pip install -r requirements.txt

# 3. ä¸‹è½½æ¨¡å‹
bash scripts/download_models.sh

# 4. å¯åŠ¨ API æœåŠ¡ (è‡ªè¡Œå°è£…)
python api_server.py  # éœ€è¦è‡ªå·±ç¼–å†™
```

##### 4.2.2 åˆ›å»ºæ•°å­—äººæ’ä»¶

```python
# textloom/services/digital_human/sadtalker_engine.py

import requests
from pathlib import Path
from typing import Dict, Any

class SadTalkerEngine:
    """SadTalker æ•°å­—äººå¼•æ“"""

    def __init__(self, api_url: str = "http://localhost:7860"):
        self.api_url = api_url

    def generate(
        self,
        source_image: str,
        audio_path: str,
        output_path: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ•°å­—äººè§†é¢‘

        Args:
            source_image: äººç‰©å›¾ç‰‡è·¯å¾„
            audio_path: éŸ³é¢‘è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        try:
            # è°ƒç”¨ SadTalker API
            with open(source_image, "rb") as img_file:
                with open(audio_path, "rb") as audio_file:
                    response = requests.post(
                        f"{self.api_url}/generate",
                        files={
                            "source_image": img_file,
                            "driven_audio": audio_file
                        },
                        data={
                            "preprocess": "crop",
                            "still_mode": True,
                            "use_enhancer": True
                        },
                        timeout=600
                    )

            # ä¿å­˜è§†é¢‘
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "wb") as f:
                f.write(response.content)

            return {
                "success": True,
                "video_path": output_path
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
```

##### 4.2.3 é›†æˆåˆ°è§†é¢‘ç”Ÿæˆæµç¨‹

```python
# textloom/services/editly_video_engine.py (æ›´æ–°)

class EditlyVideoEngine(VideoEngine):

    def __init__(
        self,
        tts_engine: Optional[TTSEngine] = None,
        digital_human_engine: Optional[Any] = None
    ):
        self.tts_engine = tts_engine
        self.digital_human_engine = digital_human_engine
        # ...

    def generate_video(self, script_data, ...):
        # 1. ç”Ÿæˆ TTS éŸ³é¢‘
        audio_files = self._generate_audio_from_scenes(...)

        # 2. ç”Ÿæˆæ•°å­—äººè§†é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
        digital_human_videos = self._generate_digital_human_videos(
            script_data["scenes"],
            audio_files
        )

        # 3. ä½¿ç”¨æ•°å­—äººè§†é¢‘æ›¿æ¢ç´ æ
        for scene, dh_video in zip(script_data["scenes"], digital_human_videos):
            if dh_video:
                scene["material_id"] = dh_video["video_id"]
                # æ·»åŠ åˆ° media_files
                media_files.append({
                    "id": dh_video["video_id"],
                    "file_url": dh_video["video_path"],
                    "filename": Path(dh_video["video_path"]).name
                })

        # 4. è½¬æ¢ä¸º Editly é…ç½®
        # 5. æ‰§è¡Œ Editly
        # ...

    def _generate_digital_human_videos(self, scenes, audio_files):
        """ä¸ºéœ€è¦æ•°å­—äººçš„åœºæ™¯ç”Ÿæˆè§†é¢‘"""
        results = []

        for scene, audio in zip(scenes, audio_files):
            if scene.get("use_digital_human"):
                result = self.digital_human_engine.generate(
                    source_image=scene.get("digital_human_image"),
                    audio_path=audio["audio_path"],
                    output_path=f"workspace/digital_human/{scene['scene_id']}.mp4"
                )
                results.append(result if result["success"] else None)
            else:
                results.append(None)

        return results
```

#### 4.3 é˜¶æ®µ 4 æµ‹è¯•

**æµ‹è¯•åœºæ™¯**:

```python
# æµ‹è¯•æ•°å­—äººç”Ÿæˆ
script_data = {
    "scenes": [
        {
            "scene_id": 1,
            "narration": "å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯æ•°å­—äººå°åŠ©æ‰‹ã€‚",
            "use_digital_human": True,
            "digital_human_image": "workspace/digital_human/avatar.png",
            "voice_id": "female_1"
        }
    ]
}

engine = EditlyVideoEngine(
    tts_engine=tts_engine,
    digital_human_engine=sadtalker_engine
)

result = engine.generate_video(
    script_data=script_data,
    media_files=[],
    output_path="test_digital_human.mp4"
)
```

#### 4.4 é˜¶æ®µ 4 äº¤ä»˜ç‰©

- [ ] SadTalker éƒ¨ç½²æ–‡æ¡£
- [ ] æ•°å­—äººæ’ä»¶ä»£ç 
- [ ] å®Œæ•´é›†æˆæµ‹è¯•
- [ ] æ•°å­—äººç´ æåº“ï¼ˆ3-5 ä¸ªè§’è‰²ï¼‰
- [ ] æ€§èƒ½å’Œæˆæœ¬åˆ†ææŠ¥å‘Š

---

## ğŸ“Š æ€»ä½“æ—¶é—´çº¿

| é˜¶æ®µ | æ—¶é—´ | ç´¯è®¡ | å…³é”®é‡Œç¨‹ç¢‘ |
|------|------|------|----------|
| é˜¶æ®µ 1 | 3-5 å¤© | 1 å‘¨ | âœ… Editly å¯ç”¨ |
| é˜¶æ®µ 2 | 1-2 å‘¨ | 3 å‘¨ | âœ… TTS é›†æˆ |
| é˜¶æ®µ 3 | 2-3 å‘¨ | 6 å‘¨ | âœ… TextLoom è¿ç§» |
| é˜¶æ®µ 4 | 3-4 å‘¨ | 10 å‘¨ | âœ… æ•°å­—äººåŠŸèƒ½ |

**æ€»è®¡**: **8-10 å‘¨** (çº¦ 2-2.5 ä¸ªæœˆ)

---

## ğŸ’° æˆæœ¬åˆ†æ

### æ–¹æ¡ˆ A: å…¨å¼€æº (æ¨è)

**ä¸€æ¬¡æ€§æˆæœ¬**:
- å¼€å‘æˆæœ¬: 2 äººæœˆ Ã— $10,000 = **$20,000**

**æœˆåº¦æˆæœ¬** (GPU æœåŠ¡å™¨):
- GPU æœåŠ¡å™¨ (RTX 3090): **$300-500/æœˆ**
- æˆ–äº‘ç«¯ GPU (AWS p3.2xlarge): **$800-1200/æœˆ**

**å¹´åº¦æ€»æˆæœ¬**: $20,000 + $6,000 = **$26,000**

### æ–¹æ¡ˆ B: æ··åˆæ–¹æ¡ˆ

**æœˆåº¦æˆæœ¬**:
- TTS: å¼€æº (å…è´¹)
- æ•°å­—äºº: HeyGen API ($0.10/ç§’)
- å‡è®¾ 30% è§†é¢‘éœ€è¦æ•°å­—äººï¼Œå¹³å‡ 30 ç§’
- 1000 è§†é¢‘/æœˆ Ã— 30% Ã— 30 ç§’ Ã— $0.10 = **$900/æœˆ**

**å¹´åº¦æ€»æˆæœ¬**: $20,000 + $10,800 = **$30,800**

### å¯¹æ¯”å•†ä¸šæ–¹æ¡ˆ

**çº¯å•†ä¸š API**:
- æœˆæˆæœ¬: **$5,000**
- å¹´æˆæœ¬: **$60,000**

**èŠ‚çœ**: $60,000 - $26,000 = **$34,000/å¹´** (**57% èŠ‚çœ**)

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

### é˜¶æ®µ 1
- [ ] Editly å®‰è£…æˆåŠŸç‡ 100%
- [ ] åŸºç¡€æµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] æ€§èƒ½æ»¡è¶³éœ€æ±‚ (< 3min/1min è§†é¢‘)

### é˜¶æ®µ 2
- [ ] TTS è´¨é‡è¯„åˆ† â‰¥ 4/5
- [ ] TTS é€Ÿåº¦ < 5s/å¥
- [ ] å£°éŸ³åº“ â‰¥ 3 ä¸ª

### é˜¶æ®µ 3
- [ ] è¿ç§»æˆåŠŸç‡ â‰¥ 95%
- [ ] åŒå¼•æ“åˆ‡æ¢æ— ç¼
- [ ] æ€§èƒ½æ— æ˜æ˜¾ä¸‹é™

### é˜¶æ®µ 4
- [ ] æ•°å­—äººè´¨é‡å¯æ¥å—
- [ ] ç”Ÿæˆé€Ÿåº¦ < 10min/1min è§†é¢‘
- [ ] æ•´ä½“æˆæœ¬é™ä½ â‰¥ 50%

---

## ğŸš¨ é£é™©ç®¡ç†

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| GPU èµ„æºä¸è¶³ | ä¸­ | é«˜ | æå‰é‡‡è´­æˆ–ç§Ÿç”¨äº‘ç«¯ GPU |
| TTS è´¨é‡ä¸è¾¾æ ‡ | ä½ | ä¸­ | å¤šæ–¹æ¡ˆå¯¹æ¯”æµ‹è¯• |
| æ•°å­—äººæ•ˆæœå·® | ä¸­ | é«˜ | ä¿ç•™ HeyGen ä½œä¸ºå¤‡é€‰ |
| å¼€å‘å‘¨æœŸè¶…æœŸ | ä¸­ | ä¸­ | åˆ†é˜¶æ®µäº¤ä»˜ï¼Œä¼˜å…ˆæ ¸å¿ƒåŠŸèƒ½ |

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### æœ¬å‘¨ (Week 1)

**Day 1-2**:
- [ ] å®‰è£… Node.js + FFmpeg
- [ ] éƒ¨ç½² Editly
- [ ] è¿è¡Œç¬¬ä¸€ä¸ªæµ‹è¯•

**Day 3-5**:
- [ ] å®Œæˆ 4 ä¸ªåŸºç¡€æµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ç¼–å†™æµ‹è¯•æŠ¥å‘Š

### ä¸‹å‘¨ (Week 2)

- [ ] è°ƒç ” GPT-SoVITS
- [ ] éƒ¨ç½² TTS ç¯å¢ƒ
- [ ] åˆæ­¥é›†æˆæµ‹è¯•

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬ä»é˜¶æ®µ 1 å¼€å§‹ï¼** ğŸš€

è¿è¡Œè¿™ä¸ªå‘½ä»¤å¯åŠ¨ç¬¬ä¸€é˜¶æ®µï¼š
```bash
cd editly
npm install
npm run build
node dist/cli.js --version
```
