# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.
<!-- æ­¤æ–‡ä»¶ä¸º Claude Code (claude.ai/code) æä¾›åœ¨æ­¤ä»£ç åº“ä¸­å·¥ä½œçš„æŒ‡å¯¼ -->

## ğŸ“š Documentation Structure
<!-- æ–‡æ¡£ç»“æ„ -->

The project uses a well-organized documentation structure under the `docs/` directory:
<!-- é¡¹ç›®ä½¿ç”¨è‰¯å¥½ç»„ç»‡çš„æ–‡æ¡£ç»“æ„ï¼Œä½äº docs/ ç›®å½•ä¸‹ -->

- **Architecture** (`docs/architecture/`): System design, architecture reviews, and logging enhancements
- **Security** (`docs/security/`): Security audits, JWT authentication, CORS configuration, and security implementation guides
- **Performance** (`docs/performance/`): Database optimization, connection pool tuning, and performance improvements
- **Deployment** (`docs/deployment/`): CI/CD pipelines and deployment guides
- **Backup** (`docs/backup/`): Backup strategies and disaster recovery procedures

For complete navigation, refer to `docs/README.md`.
<!-- å®Œæ•´å¯¼èˆªè¯·å‚è€ƒ docs/README.md -->

## Quick Commands
<!-- å¿«é€Ÿå‘½ä»¤ -->

### Development Commands
<!-- å¼€å‘å‘½ä»¤ -->
```bash

# Start all services in background (recommended for production)
# å¯åŠ¨æ‰€æœ‰æœåŠ¡åˆ°åå°
./start_all_services.sh

# Stop all services
# åœæ­¢æ‰€æœ‰æœåŠ¡
./stop_all.sh

# Install dependencies
# å®‰è£…ä¾èµ–
uv sync

# Install Playwright browsers (required for dynamic subtitles)
# å®‰è£… Playwright æµè§ˆå™¨ï¼ˆåŠ¨æ€å­—å¹•åŠŸèƒ½å¿…éœ€ï¼‰
playwright install chromium

# Run tests
# è¿è¡Œæµ‹è¯•
pytest tests/

# Start Celery services
# å¯åŠ¨ Celery æœåŠ¡ï¼ˆWorker/Flower/Beatï¼‰
./start_celery_worker.sh worker &
./start_celery_worker.sh flower &
./start_celery_worker.sh beat &

# Individual Celery service management
# å•ç‹¬çš„ Celery æœåŠ¡ç®¡ç†
./start_celery_worker.sh worker   # Start Worker only
./start_celery_worker.sh flower   # Start Flower monitoring only
./start_celery_worker.sh beat     # Start Beat scheduler only

# Start Docker services (see docker/README.md for details)
# å¯åŠ¨DockeræœåŠ¡ï¼ˆè¯¦è§docker/README.mdï¼‰
docker-compose -f docker/compose/docker-compose.yml up -d
```

### Database Management
<!-- æ•°æ®åº“ç®¡ç† -->
```bash
# Alembic migrationsï¼ˆSQLAlchemy ORM as single source of truthï¼‰
# Alembic è¿ç§»ï¼ˆSQLAlchemy ORM ä¸ºå•ä¸€äº‹å®æ¥æºï¼‰
uv run alembic revision --autogenerate -m "sync models to db"
uv run alembic upgrade head
```

### Code Quality
<!-- ä»£ç è´¨é‡ -->
```bash
# Format code
# æ ¼å¼åŒ–ä»£ç 
uv run black .

# Sort imports
# æ’åºå¯¼å…¥
uv run isort .

# Type checking
# ç±»å‹æ£€æŸ¥
uv run mypy .

# Linting
# ä»£ç æ£€æŸ¥
uv run flake8 .
```

### Testing
<!-- æµ‹è¯• -->
```bash

# Run business e2e tests
# è¿è¡Œä¸šåŠ¡ç«¯åˆ°ç«¯æµ‹è¯•
uv run python business_e2e_test.py

# Run PyCaps dynamic subtitles integration tests
# è¿è¡ŒPyCapsåŠ¨æ€å­—å¹•é›†æˆæµ‹è¯•
export RUN_LIVE_AI_TESTS=1
export INTERNAL_TEST_TOKEN=test-token
uv run pytest tests/integration/test_dynamic_subtitles_live.py -v

```

## Internal Evaluation Endpoints (dev/staging only)
<!-- å†…éƒ¨è¯„ä¼°æ¥å£ï¼ˆä»… dev/stagingï¼‰ -->

The following endpoints are exposed for rapid iteration of prompts/models. Protect with `INTERNAL_TEST_TOKEN` and send `x-test-token` header. Do not enable in production.
<!-- ä»¥ä¸‹ç«¯ç‚¹ç”¨äºæç¤ºè¯/æ¨¡å‹çš„å¿«é€Ÿè¿­ä»£éªŒè¯ã€‚é€šè¿‡ INTERNAL_TEST_TOKEN ä¿æŠ¤ï¼Œå¹¶åœ¨è¯·æ±‚å¤´æºå¸¦ x-test-tokenã€‚ç”Ÿäº§ç¯å¢ƒè¯·å‹¿å¼€å¯ã€‚ -->

- Image analysis with context: `POST /internal/analyzer/analyze-image`
- Material extract/download: `POST /internal/materials/extract-media`, `POST /internal/materials/download-and-organize`
- Script generation: `POST /internal/script/generate`
- Video generation: `POST /internal/video/generate-single`, `POST /internal/video/generate-multiple`

Example (script generation):
```bash
curl -X POST http://localhost:48095/internal/script/generate \
  -H "Content-Type: application/json" \
  -H "x-test-token: ${INTERNAL_TEST_TOKEN}" \
  -d '{
    "topic": "AI å·¥å…·è¶‹åŠ¿",
    "source_content": "è¿‘å¹´ç”Ÿæˆå¼ AI å·¥å…·çˆ†å‘...",
    "styles": ["professional", "viral"],
    "material_context": {"summary": {"total_count": 2, "image_count": 1, "video_count": 1}}
  }'
```

Example (video generation):
```bash
curl -X POST http://localhost:48095/internal/video/generate-single \
  -H "Content-Type: application/json" \
  -H "x-test-token: ${INTERNAL_TEST_TOKEN}" \
  -d '{
    "script_data": {
      "narration": "è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ—ç™½",
      "scenes": [{"scene_id": 1, "narration": "ç‰‡å¤´ä»‹ç»", "material_id": "mat1"}]
    },
    "media_files": [
      {"id": "mat1", "file_url": "https://example.com/a.jpg", "filename": "a.jpg"}
    ],
    "mode": "multi_scene"
  }'
```

Run live integration tests (optional, controlled):
<!-- è¿è¡ŒçœŸè¿ç½‘é›†æˆæµ‹è¯•ï¼ˆå¯é€‰ï¼Œå—æ§ï¼‰ -->
```bash
export RUN_LIVE_AI_TESTS=1
uv run pytest tests/integration/test_internal_endpoints_live.py -q
```

## Architecture Overview
<!-- æ¶æ„æ¦‚è¿° -->

TextLoom is an intelligent text-to-video generation system built with FastAPI and Celery that converts Markdown documents into professional video content using AI-powered analysis and script generation. The system now uses a distributed architecture with Celery and Redis for scalable background task processing.
<!-- TextLoom æ˜¯ä¸€ä¸ªåŸºäº FastAPI å’Œ Celery æ„å»ºçš„æ™ºèƒ½æ–‡æœ¬è½¬è§†é¢‘ç”Ÿæˆç³»ç»Ÿï¼Œä½¿ç”¨ AI é©±åŠ¨çš„åˆ†æå’Œè„šæœ¬ç”Ÿæˆå°† Markdown æ–‡æ¡£è½¬æ¢ä¸ºä¸“ä¸šè§†é¢‘å†…å®¹ã€‚ç³»ç»Ÿç°åœ¨ä½¿ç”¨åŸºäº Celery å’Œ Redis çš„åˆ†å¸ƒå¼æ¶æ„æ¥å®ç°å¯æ‰©å±•çš„åå°ä»»åŠ¡å¤„ç† -->

### Core Architecture Components
<!-- æ ¸å¿ƒæ¶æ„ç»„ä»¶ -->

**FastAPI Application** (`main.py`)
<!-- FastAPI åº”ç”¨ç¨‹åº -->
- Entry point with CORS middleware <!-- å¸¦ CORS ä¸­é—´ä»¶çš„å…¥å£ç‚¹ -->
- Health checks and status endpoints <!-- å¥åº·æ£€æŸ¥å’ŒçŠ¶æ€ç«¯ç‚¹ -->
- Task submission API endpoints <!-- ä»»åŠ¡æäº¤APIç«¯ç‚¹ -->
- Database connection lifecycle management <!-- æ•°æ®åº“è¿æ¥ç”Ÿå‘½å‘¨æœŸç®¡ç† -->

**Celery + Redis Architecture** (`celery_config.py`, `tasks/`)
<!-- Celery + Redis æ¶æ„ -->
- Distributed task queue with Redis as message broker <!-- ä½¿ç”¨Redisä½œä¸ºæ¶ˆæ¯ä»£ç†çš„åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ— -->
- Horizontal scaling with multiple Worker processes <!-- æ”¯æŒå¤šWorkerè¿›ç¨‹çš„æ°´å¹³æ‰©å±• -->
- Task retry and error handling mechanisms <!-- ä»»åŠ¡é‡è¯•å’Œé”™è¯¯å¤„ç†æœºåˆ¶ -->
- Real-time progress tracking and status updates <!-- å®æ—¶è¿›åº¦è·Ÿè¸ªå’ŒçŠ¶æ€æ›´æ–° -->
- Flower monitoring dashboard for task visualization <!-- ç”¨äºä»»åŠ¡å¯è§†åŒ–çš„Flowerç›‘æ§é¢æ¿ -->

**Database Layer** (`models/`)
<!-- æ•°æ®åº“å±‚ -->
- PostgreSQL with async SQLAlchemy <!-- ä½¿ç”¨å¼‚æ­¥ SQLAlchemy çš„ PostgreSQL -->
- Supabase integration support <!-- Supabase é›†æˆæ”¯æŒ -->
- Custom connection pooling with pgbouncer compatibility <!-- ä¸ pgbouncer å…¼å®¹çš„è‡ªå®šä¹‰è¿æ¥æ±  -->
- Schema: `textloom_core` namespace <!-- æ¨¡å¼ï¼štextloom_core å‘½åç©ºé—´ -->
- Enhanced task tracking with Celery integration fields <!-- å¢å¼ºçš„ä»»åŠ¡è·Ÿè¸ªï¼ŒåŒ…å«Celeryé›†æˆå­—æ®µ -->

**Processing Pipeline** (Celery Tasks):
<!-- å¤„ç†æµæ°´çº¿ï¼ˆCeleryä»»åŠ¡ï¼‰-->
1. **Material Processing** (0-25%): Extract and download media from documents
   <!-- ç´ æå¤„ç†ï¼šä»æ–‡æ¡£ä¸­æå–å’Œä¸‹è½½åª’ä½“ -->
2. **Material Analysis** (25-50%): AI-powered content analysis 
   <!-- ç´ æåˆ†æï¼šAI é©±åŠ¨çš„å†…å®¹åˆ†æ -->
3. **Script Generation** (50-75%): Generate video scripts from content
   <!-- è„šæœ¬ç”Ÿæˆï¼šä»å†…å®¹ç”Ÿæˆè§†é¢‘è„šæœ¬ -->
4. **Video Generation** (75-100%): Compose final video output
   <!-- è§†é¢‘ç”Ÿæˆï¼šåˆæˆæœ€ç»ˆè§†é¢‘è¾“å‡º -->

Each stage is implemented as a Celery task with progress callbacks and error handling.
<!-- æ¯ä¸ªé˜¶æ®µéƒ½å®ç°ä¸ºå¸¦æœ‰è¿›åº¦å›è°ƒå’Œé”™è¯¯å¤„ç†çš„Celeryä»»åŠ¡ -->

### Key Models and Status Flow
<!-- å…³é”®æ¨¡å‹å’ŒçŠ¶æ€æµ -->

**Task Status Flow**:
<!-- ä»»åŠ¡çŠ¶æ€æµ -->
`pending` â†’ `processing` â†’ `completed` / `failed` / `cancelled`
<!-- å¾…å¤„ç† â†’ å¤„ç†ä¸­ â†’ å·²å®Œæˆ / å¤±è´¥ / å·²å–æ¶ˆ -->

**Task Types**:
<!-- ä»»åŠ¡ç±»å‹ -->
- `TEXT_TO_VIDEO`: Full pipeline processing <!-- å®Œæ•´æµæ°´çº¿å¤„ç† -->
- `VIDEO_GENERATION`: Video composition only <!-- ä»…è§†é¢‘åˆæˆ -->
- `DYNAMIC_SUBTITLE`: PyCaps dynamic subtitle generation <!-- PyCapsåŠ¨æ€å­—å¹•ç”Ÿæˆ -->

**Multi-Video Support**:
<!-- å¤šè§†é¢‘æ”¯æŒ -->
- Single task can generate multiple video variants <!-- å•ä¸ªä»»åŠ¡å¯ç”Ÿæˆå¤šä¸ªè§†é¢‘å˜ä½“ -->
- Sub-video tasks track individual video generation <!-- å­è§†é¢‘ä»»åŠ¡è·Ÿè¸ªå•ä¸ªè§†é¢‘ç”Ÿæˆ -->
- Configurable video count via `multi_video_count` <!-- é€šè¿‡ multi_video_count é…ç½®è§†é¢‘æ•°é‡ -->

## Database Architecture
<!-- æ•°æ®åº“æ¶æ„ -->

### Connection Management
<!-- è¿æ¥ç®¡ç† -->
- Uses `asyncpg` with SQLAlchemy async <!-- ä½¿ç”¨ asyncpg å’Œ SQLAlchemy å¼‚æ­¥ -->
- Connection pooling optimized for pgbouncer <!-- ä¸º pgbouncer ä¼˜åŒ–çš„è¿æ¥æ±  -->
- Prepared statements disabled for compatibility <!-- ä¸ºå…¼å®¹æ€§ç¦ç”¨é¢„å¤„ç†è¯­å¥ -->
- Custom session management with automatic rollback <!-- å¸¦è‡ªåŠ¨å›æ»šçš„è‡ªå®šä¹‰ä¼šè¯ç®¡ç† -->

### Key Tables Structure
<!-- å…³é”®è¡¨ç»“æ„ -->
- `tasks`: Main task tracking with comprehensive metadata <!-- ä¸»ä»»åŠ¡è·Ÿè¸ªåŠç»¼åˆå…ƒæ•°æ® -->
- `media_items`: Media file references and metadata <!-- åª’ä½“æ–‡ä»¶å¼•ç”¨å’Œå…ƒæ•°æ® -->
- `material_analyses`: AI analysis results <!-- AI åˆ†æç»“æœ -->
- `personas`: Content generation personas/styles <!-- å†…å®¹ç”Ÿæˆäººè®¾/é£æ ¼ -->
- `script_content`: Generated scripts and prompts <!-- ç”Ÿæˆçš„è„šæœ¬å’Œæç¤ºè¯ -->
- `sub_video_tasks`: Individual video generation tracking <!-- å•ä¸ªè§†é¢‘ç”Ÿæˆè·Ÿè¸ª -->

### Schema Organization
<!-- æ¨¡å¼ç»„ç»‡ -->
All tables use the `textloom_core` schema namespace.
<!-- æ‰€æœ‰è¡¨éƒ½ä½¿ç”¨ textloom_core æ¨¡å¼å‘½åç©ºé—´ -->

## PyCaps Dynamic Subtitle Integration
<!-- PyCapsåŠ¨æ€å­—å¹•é›†æˆ -->

TextLoom integrates the open-source [PyCaps](https://github.com/francozanardi/pycaps) library for professional dynamic subtitle generation.
<!-- TextLoomé›†æˆå¼€æºPyCapsåº“ç”¨äºä¸“ä¸šåŠ¨æ€å­—å¹•ç”Ÿæˆ -->

**Key Components**:
<!-- å…³é”®ç»„ä»¶ -->
- **PyCaps Service** (`services/pycaps_subtitle_service.py`): Main integration service <!-- ä¸»è¦é›†æˆæœåŠ¡ -->
- **SRT Converter** (`services/pycaps_converter.py`): Converts SRT to PyCaps JSON format <!-- SRTè½¬PyCaps JSONæ ¼å¼è½¬æ¢å™¨ -->  
- **Template System**: Built-in templates (hype, minimalist, explosive, vibrant) <!-- å†…ç½®æ¨¡æ¿ç³»ç»Ÿ -->
- **Async Processing**: Thread isolation to avoid FastAPI/Playwright conflicts <!-- å¼‚æ­¥å¤„ç†ï¼šçº¿ç¨‹éš”ç¦»é¿å…å†²çª -->

**Processing Flow**:
<!-- å¤„ç†æµç¨‹ -->
1. Download video and SRT files <!-- ä¸‹è½½è§†é¢‘å’ŒSRTæ–‡ä»¶ -->
2. Convert SRT to word-level JSON format <!-- è½¬æ¢SRTä¸ºè¯çº§JSONæ ¼å¼ -->
3. Apply PyCaps template rendering with Playwright/Chromium <!-- åº”ç”¨PyCapsæ¨¡æ¿æ¸²æŸ“ -->
4. Upload processed video to storage <!-- ä¸Šä¼ å¤„ç†åçš„è§†é¢‘åˆ°å­˜å‚¨ -->

**Template Management**:
<!-- æ¨¡æ¿ç®¡ç† -->
- Templates are managed by `TemplateService` and `TemplateFactory` <!-- é€šè¿‡TemplateServiceå’ŒTemplateFactoryç®¡ç†æ¨¡æ¿ -->
- No custom template code - uses PyCaps built-in templates only <!-- ä¸ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ä»£ç ï¼Œä»…ä½¿ç”¨PyCapså†…ç½®æ¨¡æ¿ -->
- Word-level timing automatically distributed from sentence-level SRT data <!-- è¯çº§æ—¶é—´æˆ³ä»å¥çº§SRTæ•°æ®è‡ªåŠ¨åˆ†é… -->

## Configuration System
<!-- é…ç½®ç³»ç»Ÿ -->

**Environment-based**: Uses Pydantic Settings with `.env` file support
<!-- åŸºäºç¯å¢ƒï¼šä½¿ç”¨ Pydantic Settings å’Œ .env æ–‡ä»¶æ”¯æŒ -->

**Key Configuration Areas**:
<!-- å…³é”®é…ç½®åŒºåŸŸ -->
- **AI Models**: Supports OpenAI, Gemini, custom endpoints <!-- AI æ¨¡å‹ï¼šæ”¯æŒ OpenAIã€Geminiã€è‡ªå®šä¹‰ç«¯ç‚¹ -->
- **Video Generation**: Custom video service integration <!-- è§†é¢‘ç”Ÿæˆï¼šè‡ªå®šä¹‰è§†é¢‘æœåŠ¡é›†æˆ -->
- **Storage**: MinIO, Huawei OBS support <!-- å­˜å‚¨ï¼šMinIOã€åä¸º OBS æ”¯æŒ -->
- **Database**: PostgreSQL/Supabase with connection tuning <!-- æ•°æ®åº“ï¼šPostgreSQL/Supabase è¿æ¥è°ƒä¼˜ -->
- **Task Processing**: Concurrency, timeouts, polling intervals <!-- ä»»åŠ¡å¤„ç†ï¼šå¹¶å‘ã€è¶…æ—¶ã€è½®è¯¢é—´éš” -->
- **Dynamic Subtitles**: PyCaps engine configuration and template management <!-- åŠ¨æ€å­—å¹•ï¼šPyCapså¼•æ“é…ç½®å’Œæ¨¡æ¿ç®¡ç† -->

**Model Switching**: 
<!-- æ¨¡å‹åˆ‡æ¢ -->
- `use_gemini=True` switches to Google Gemini models <!-- use_gemini=True åˆ‡æ¢åˆ° Google Gemini æ¨¡å‹ -->
- Separate image analysis model configuration <!-- ç‹¬ç«‹çš„å›¾åƒåˆ†ææ¨¡å‹é…ç½® -->
- Per-task model selection support <!-- æ¯ä»»åŠ¡æ¨¡å‹é€‰æ‹©æ”¯æŒ -->

## API Architecture
<!-- API æ¶æ„ -->

### Router Organization
<!-- è·¯ç”±ç»„ç»‡ -->
- `/tasks`: Task management and video generation <!-- ä»»åŠ¡ç®¡ç†å’Œè§†é¢‘ç”Ÿæˆ -->
- `/personas`: Content generation personas <!-- å†…å®¹ç”Ÿæˆäººè®¾ -->
- `/auth`: JWT authentication and user management <!-- JWT è®¤è¯å’Œç”¨æˆ·ç®¡ç† -->
- `/secure-tasks`: Secure task operations with authentication <!-- å¸¦è®¤è¯çš„å®‰å…¨ä»»åŠ¡æ“ä½œ -->
- `/dynamic-subtitles`: Dynamic subtitle generation <!-- åŠ¨æ€å­—å¹•ç”Ÿæˆ -->
- `/internal/*`: Internal evaluation endpoints (dev/staging only) <!-- å†…éƒ¨è¯„ä¼°ç«¯ç‚¹ï¼ˆä»… dev/stagingï¼‰ -->

### Key API Patterns
<!-- å…³é”® API æ¨¡å¼ -->
- Async/await throughout <!-- å…¨ç¨‹ä½¿ç”¨ Async/await -->
- Background task submission via scheduler <!-- é€šè¿‡è°ƒåº¦å™¨æäº¤åå°ä»»åŠ¡ -->
- File upload handling with size limits <!-- å¸¦å¤§å°é™åˆ¶çš„æ–‡ä»¶ä¸Šä¼ å¤„ç† -->
- Progress tracking via polling endpoints <!-- é€šè¿‡è½®è¯¢ç«¯ç‚¹è·Ÿè¸ªè¿›åº¦ -->

### Error Handling
<!-- é”™è¯¯å¤„ç† -->
- Structured error responses <!-- ç»“æ„åŒ–é”™è¯¯å“åº” -->
- Background task error capture <!-- åå°ä»»åŠ¡é”™è¯¯æ•è· -->
- Timeout and recovery mechanisms <!-- è¶…æ—¶å’Œæ¢å¤æœºåˆ¶ -->

## Development Patterns
<!-- å¼€å‘æ¨¡å¼ -->

### Adding New Processing Steps
<!-- æ·»åŠ æ–°çš„å¤„ç†æ­¥éª¤ -->
1. Extend `TaskProcessor` in `services/` <!-- åœ¨ services/ ä¸­æ‰©å±• TaskProcessor -->
2. Update progress percentage ranges <!-- æ›´æ–°è¿›åº¦ç™¾åˆ†æ¯”èŒƒå›´ -->
3. Add status tracking in database models <!-- åœ¨æ•°æ®åº“æ¨¡å‹ä¸­æ·»åŠ çŠ¶æ€è·Ÿè¸ª -->
4. Implement error handling and rollback <!-- å®ç°é”™è¯¯å¤„ç†å’Œå›æ»š -->

### Database Operations
<!-- æ•°æ®åº“æ“ä½œ -->
- Always use `get_db_session()` context manager <!-- å§‹ç»ˆä½¿ç”¨ get_db_session() ä¸Šä¸‹æ–‡ç®¡ç†å™¨ -->
- Implement proper transaction handling <!-- å®ç°æ­£ç¡®çš„äº‹åŠ¡å¤„ç† -->
- Use model conversion functions for type safety <!-- ä½¿ç”¨æ¨¡å‹è½¬æ¢å‡½æ•°ç¡®ä¿ç±»å‹å®‰å…¨ -->
- Handle connection pooling edge cases <!-- å¤„ç†è¿æ¥æ± è¾¹ç¼˜æƒ…å†µ -->

### Background Tasks
<!-- åå°ä»»åŠ¡ -->
- Use Celery for distributed task processing <!-- ä½¿ç”¨ Celery è¿›è¡Œåˆ†å¸ƒå¼ä»»åŠ¡å¤„ç† -->
- Implement timeout handling and retry mechanisms <!-- å®ç°è¶…æ—¶å¤„ç†å’Œé‡è¯•æœºåˆ¶ -->
- Track task states in database with Celery task IDs <!-- åœ¨æ•°æ®åº“ä¸­è·Ÿè¸ªä»»åŠ¡çŠ¶æ€åŠ Celery ä»»åŠ¡ ID -->
- Use Redis as message broker for task queuing <!-- ä½¿ç”¨ Redis ä½œä¸ºä»»åŠ¡é˜Ÿåˆ—çš„æ¶ˆæ¯ä»£ç† -->

### Testing
<!-- æµ‹è¯• -->
- Integration tests simulate full workflows <!-- é›†æˆæµ‹è¯•æ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµ -->
- Business e2e tests validate core user journeys <!-- ä¸šåŠ¡ç«¯åˆ°ç«¯æµ‹è¯•éªŒè¯æ ¸å¿ƒç”¨æˆ·æ—…ç¨‹ -->
- Use `--verbose` flag for detailed test output <!-- ä½¿ç”¨ --verbose æ ‡å¿—è·å–è¯¦ç»†æµ‹è¯•è¾“å‡º -->
- Database tests require running Supabase instance <!-- æ•°æ®åº“æµ‹è¯•éœ€è¦è¿è¡Œ Supabase å®ä¾‹ -->

## Storage and Media Handling
<!-- å­˜å‚¨å’Œåª’ä½“å¤„ç† -->

**Workspace Structure**:
<!-- å·¥ä½œç©ºé—´ç»“æ„ -->
```
workspace/
â”œâ”€â”€ materials/          # Downloaded source materials ä¸‹è½½çš„æºç´ æ
â”‚   â”œâ”€â”€ images/         # å›¾ç‰‡
â”‚   â”œâ”€â”€ videos/         # è§†é¢‘
â”‚   â””â”€â”€ audio/          # éŸ³é¢‘
â”œâ”€â”€ processed/          # Processed outputs å¤„ç†åçš„è¾“å‡º
â”œâ”€â”€ keyframes/          # Video keyframe extraction è§†é¢‘å…³é”®å¸§æå–
â””â”€â”€ logs/              # Processing logs å¤„ç†æ—¥å¿—
```

**File Upload Limits**:
<!-- æ–‡ä»¶ä¸Šä¼ é™åˆ¶ -->
- Max file size: 50MB <!-- æœ€å¤§æ–‡ä»¶å¤§å°ï¼š50MB -->
- Max images per task: 20 <!-- æ¯ä¸ªä»»åŠ¡æœ€å¤š 20 å¼ å›¾ç‰‡ -->
- Max videos per task: 5 <!-- æ¯ä¸ªä»»åŠ¡æœ€å¤š 5 ä¸ªè§†é¢‘ -->

## Logging and Debugging
<!-- æ—¥å¿—å’Œè°ƒè¯• -->

**Log Files**:
<!-- æ—¥å¿—æ–‡ä»¶ -->
- `logs/app.log`: Application logs <!-- åº”ç”¨ç¨‹åºæ—¥å¿— -->
- `logs/textloom.log`: Server logs <!-- æœåŠ¡å™¨æ—¥å¿— -->
- `logs/textloom_error.log`: Error logs <!-- é”™è¯¯æ—¥å¿— -->
- `workspace/logs/material_analysis.log`: Analysis logs <!-- åˆ†ææ—¥å¿— -->

**Health Endpoints**:
<!-- å¥åº·æ£€æŸ¥ç«¯ç‚¹ -->
- `/health`: Service health check with database status <!-- æœåŠ¡å¥åº·æ£€æŸ¥ï¼ŒåŒ…å«æ•°æ®åº“çŠ¶æ€ -->
- `/`: Basic service info and Celery status <!-- åŸºæœ¬æœåŠ¡ä¿¡æ¯å’ŒCeleryçŠ¶æ€ -->

**Task Monitoring**:
<!-- ä»»åŠ¡ç›‘æ§ -->
- Use `/tasks/{task_id}/status` for progress polling <!-- ä½¿ç”¨ /tasks/{task_id}/status è¿›è¡Œè¿›åº¦è½®è¯¢ -->
- Use `/health` for service health checks <!-- ä½¿ç”¨ /health è¿›è¡ŒæœåŠ¡å¥åº·æ£€æŸ¥ -->
- Celery task status and Worker monitoring via Flower dashboard <!-- é€šè¿‡Flowerä»ªè¡¨æ¿ç›‘æ§Celeryä»»åŠ¡çŠ¶æ€å’ŒWorker -->
- Database connection monitoring in health checks <!-- å¥åº·æ£€æŸ¥ä¸­çš„æ•°æ®åº“è¿æ¥ç›‘æ§ -->

## Documentation Management
<!-- æ–‡æ¡£ç®¡ç† -->

**Adding New Documentation**:
<!-- æ·»åŠ æ–°æ–‡æ¡£ -->
- Place documents in appropriate `docs/` subdirectories based on their purpose
- Update `docs/README.md` index when adding new documents  
- Follow the established naming conventions and structure
- Include both English and Chinese documentation where applicable

**Documentation Guidelines**:
<!-- æ–‡æ¡£æŒ‡å¯¼åŸåˆ™ -->
- Keep technical documents in `docs/` rather than project root
- Use clear, descriptive filenames (e.g., `SECURITY_AUDIT_REPORT.md`)
- Maintain consistent markdown formatting and structure
- Update cross-references when moving or renaming documents

## Configuration File Management
<!-- é…ç½®æ–‡ä»¶ç®¡ç† -->

**âš ï¸ CRITICAL RULES for Configuration Files**:
<!-- é…ç½®æ–‡ä»¶å…³é”®è§„åˆ™ -->

**Never modify user's `.env` file without explicit confirmation**:
<!-- ä¸¥ç¦æœªç»ç¡®è®¤ä¿®æ”¹ç”¨æˆ·çš„.envæ–‡ä»¶ -->
- Contains sensitive production configuration
- Changes can cause service interruption
- Always ask for confirmation before any `.env` modifications

**Single Configuration Template Policy**:
<!-- å•ä¸€é…ç½®æ¨¡æ¿æ”¿ç­– -->
- Only use `.env.example` as the configuration template
- Never create multiple template files (env.example, .env.template, etc.)
- Avoid user confusion about which version is correct

**Configuration File Standards**:
<!-- é…ç½®æ–‡ä»¶æ ‡å‡† -->
- `.env` - Actual runtime configuration (never commit to git)
- `.env.example` - Complete configuration template (commit to git)
- Use placeholder values in template (your-api-key, your-password)
- Provide detailed comments for all configuration sections

**Before modifying any configuration**:
<!-- ä¿®æ”¹ä»»ä½•é…ç½®å‰å¿…é¡» -->
1. Ask for user confirmation
2. Create backup if needed
3. Clearly explain what will be changed
4. Verify the change won't break existing functionality

Detailed configuration management guidelines: `docs/deployment/CONFIG_FILE_MANAGEMENT.md`
<!-- è¯¦ç»†é…ç½®ç®¡ç†æŒ‡å¯¼ï¼šdocs/deployment/CONFIG_FILE_MANAGEMENT.md -->

# important-instruction-reminders
<!-- é‡è¦æŒ‡ä»¤æé†’ -->

Do what has been asked; nothing more, nothing less.
NEVER create files unless they're absolutely necessary for achieving your goal.
ALWAYS prefer editing an existing file to creating a new one.
NEVER proactively create documentation files (*.md) or README files. Only create documentation files if explicitly requested by the User.

**ğŸš¨ CRITICAL: Configuration File Protection**
<!-- å…³é”®ï¼šé…ç½®æ–‡ä»¶ä¿æŠ¤ -->
NEVER modify .env files without explicit user confirmation.
NEVER create multiple configuration template files.
ALWAYS use .env.example as the single source of truth for configuration templates.
ANY configuration changes must be approved by the user first.

IMPORTANT: this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task.