"""
Celeryä»»åŠ¡æ¨¡å— - è§†é¢‘å¤„ç†ç›¸å…³ä»»åŠ¡
å°†åŸæœ‰çš„APScheduleråå°ä»»åŠ¡é‡æ„ä¸ºCeleryåˆ†å¸ƒå¼ä»»åŠ¡
ä½¿ç”¨åŒæ­¥æ•°æ®åº“è¿æ¥ï¼Œå®Œå…¨ç‹¬ç«‹äºFastAPIçš„å¼‚æ­¥æ•°æ®åº“
"""

import logging
import traceback
from datetime import datetime
from typing import Any, Dict, Optional

from celery import Task
from celery.exceptions import Retry

from celery_config import celery_app
from models.celery_db import (
    close_sync_connection_pool,
    sync_check_database_health,
    sync_get_task_by_id,
    sync_update_task_status,
    sync_update_task_with_results,
)
from models.task import TaskStatus
from utils.task_validation import validate_task_exists, log_task_consistency_info

logger = logging.getLogger(__name__)


class CallbackTask(Task):
    """å¸¦å›è°ƒå’ŒçŠ¶æ€æ›´æ–°çš„ä»»åŠ¡åŸºç±»"""

    def on_success(self, retval, task_id, args, kwargs):
        """ä»»åŠ¡æˆåŠŸå®Œæˆå›è°ƒ"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯è·³è¿‡çš„ä»»åŠ¡
        if isinstance(retval, dict) and retval.get('status') == 'skipped':
            logger.info(f"Task {task_id} was skipped: {retval.get('reason', 'unknown')}")
        else:
            logger.info(f"Task {task_id} completed successfully: {retval}")

    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """ä»»åŠ¡å¤±è´¥å›è°ƒ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯Ignoreå¼‚å¸¸ï¼ˆä»»åŠ¡è¢«è·³è¿‡ï¼‰
            from celery.exceptions import Ignore
            if isinstance(exc, Ignore):
                logger.info(f"Task {task_id} was ignored (skipped)")
                return
            
            logger.error(f"Task {task_id} failed with error: {exc}")
            logger.error(f"Traceback: {einfo}")
            # å°è¯•æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            if args and len(args) > 0:
                task_db_id = args[0]
                sync_update_task_status(
                    task_db_id,
                    TaskStatus.FAILED,
                    {
                        "error_message": str(exc),
                        "error_traceback": str(einfo),
                        "completed_at": datetime.utcnow(),
                    },
                )
        except Exception as callback_exc:
            logger.error(f"Error in on_failure callback: {callback_exc}")
            # ç¡®ä¿ä¸ä¼šå› ä¸ºå›è°ƒé”™è¯¯è€Œå¯¼è‡´æ›´ä¸¥é‡çš„é—®é¢˜

    def on_retry(self, exc, task_id, args, kwargs, einfo):
        """ä»»åŠ¡é‡è¯•å›è°ƒ"""
        try:
            logger.warning(f"Task {task_id} is being retried due to: {exc}")
            # æ›´æ–°é‡è¯•æ¬¡æ•°
            if args and len(args) > 0:
                task_db_id = args[0]
                task_info = sync_get_task_by_id(task_db_id)
                if task_info:
                    retry_count = task_info.get("retry_count", 0) + 1
                    sync_update_task_status(
                        task_db_id, TaskStatus.PROCESSING, {"retry_count": retry_count}
                    )
        except Exception as callback_exc:
            logger.error(f"Error in on_retry callback: {callback_exc}")


@celery_app.task(
    bind=True,
    base=CallbackTask,
    queue="video_processing",
    autoretry_for=(Exception,),
    retry_kwargs={"max_retries": 3, "countdown": 60},
    time_limit=3600,  # 1å°æ—¶è¶…æ—¶
    soft_time_limit=3300,  # 55åˆ†é’Ÿè½¯è¶…æ—¶
)
@validate_task_exists
def process_text_to_video(
    self,
    task_id: str,
    source_file: str,
    workspace_dir: str,
    mode: str = "multi_scene",
    persona_id: Optional[int] = None,
    multi_video_count: int = 1,
):
    """
    å¤„ç†æ–‡æœ¬è½¬è§†é¢‘çš„å®Œæ•´æµç¨‹

    Args:
        task_id: æ•°æ®åº“ä¸­çš„ä»»åŠ¡ID
        source_file: æºæ–‡ä»¶è·¯å¾„
        workspace_dir: å·¥ä½œç›®å½•
        mode: å¤„ç†æ¨¡å¼ (multi_scene/single_scene)
        persona_id: äººè®¾ID
        multi_video_count: å¤šè§†é¢‘ç”Ÿæˆæ•°é‡
    """
    try:
        task_start_time = datetime.utcnow()
        logger.info(f"ğŸš€ å¼€å§‹æ–‡æœ¬è½¬è§†é¢‘ä»»åŠ¡ - ä»»åŠ¡ID: {task_id}")
        logger.info(
            f"ä»»åŠ¡å‚æ•°:\n"
            f"  â€¢ æºæ–‡ä»¶: {source_file}\n"
            f"  â€¢ å·¥ä½œç›®å½•: {workspace_dir}\n"
            f"  â€¢ æ¨¡å¼: {mode}\n"
            f"  â€¢ äººè®¾id: {persona_id}\n"
            f"  â€¢ å¤šè§†é¢‘æ•°: {multi_video_count}\n"
            f"  â€¢ Worker: {self.request.hostname}\n"
            f"  â€¢ Celeryä»»åŠ¡ID: {self.request.id}"
        )

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        self.update_state(
            state="PROCESSING",
            meta={
                "progress": 0,
                "stage": "initialization",
                "message": "Starting task processing...",
                "worker_name": self.request.hostname,
            },
        )

        # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€ï¼ˆä½¿ç”¨åŒæ­¥æ–¹æ³•ï¼‰
        sync_update_task_status(
            task_id,
            TaskStatus.PROCESSING,
            {
                "celery_task_id": self.request.id,
                "worker_name": self.request.hostname,
                "started_at": datetime.utcnow(),
            },
        )

        # è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(progress: int, stage: str, message: str):
            callback_start = datetime.utcnow()
            self.update_state(
                state="PROCESSING",
                meta={
                    "progress": progress,
                    "stage": stage,
                    "message": message,
                    "worker_name": self.request.hostname,
                },
            )
            # åŒæ—¶æ›´æ–°æ•°æ®åº“ä¸­çš„è¿›åº¦
            sync_update_task_status(
                task_id, TaskStatus.PROCESSING, {"progress": progress}
            )
            callback_duration = (datetime.utcnow() - callback_start).total_seconds()
            logger.debug(
                f"è¿›åº¦æ›´æ–° - {progress}% | {stage} | {message} (è€—æ—¶: {callback_duration:.3f}s)"
            )

        # ç›´æ¥ä½¿ç”¨åŒæ­¥æ–¹å¼å¤„ç†ä»»åŠ¡
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬çš„ä»»åŠ¡å¤„ç†å™¨
        logger.info(f"åˆå§‹åŒ–åŒæ­¥ä»»åŠ¡å¤„ç†å™¨ - workspace: {workspace_dir}")
        processor_start_time = datetime.utcnow()

        from services.sync_task_processor import SyncTaskProcessor

        processor = SyncTaskProcessor(workspace_dir)
        processor_init_duration = (
            datetime.utcnow() - processor_start_time
        ).total_seconds()
        logger.debug(f"ä»»åŠ¡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ - è€—æ—¶: {processor_init_duration:.3f}s")

        # æ‰§è¡Œä»»åŠ¡å¤„ç†
        logger.info(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡å¤„ç† - ä»»åŠ¡ID: {task_id}")
        processing_start_time = datetime.utcnow()

        result = processor.process_text_to_video_task(
            task_id=task_id,
            source_file=source_file,
            workspace_dir=workspace_dir,
            mode=mode,
            persona_id=persona_id,
            multi_video_count=multi_video_count,
            progress_callback=progress_callback,
        )

        processing_duration = (
            datetime.utcnow() - processing_start_time
        ).total_seconds()
        logger.info(f"ä»»åŠ¡å¤„ç†å®Œæˆ - è€—æ—¶: {processing_duration:.2f}s")

        # æ ¹æ®å¤„ç†å™¨è¿”å›ç»“æœçš„çŠ¶æ€æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡çŠ¶æ€
        db_update_start = datetime.utcnow()
        final_status = result.get("status") if isinstance(result, dict) else None
        if final_status in (TaskStatus.COMPLETED, "completed"):
            sync_update_task_status(
                task_id, TaskStatus.COMPLETED, {"completed_at": datetime.utcnow()}
            )
        elif final_status in (TaskStatus.PARTIAL_SUCCESS, "partial_success"):
            sync_update_task_status(
                task_id, TaskStatus.PARTIAL_SUCCESS, {"completed_at": datetime.utcnow()}
            )
        elif final_status in (TaskStatus.PROCESSING, "processing"):
            # ä»åœ¨è¿›è¡Œä¸­ï¼šä¿æŒprocessingï¼Œç”±è½®è¯¢ä»»åŠ¡æ”¶æ•›åˆ°æœ€ç»ˆæ€
            sync_update_task_status(
                task_id,
                TaskStatus.PROCESSING,
                "å­è§†é¢‘ä»»åŠ¡è¿›è¡Œä¸­ï¼Œç­‰å¾…åˆæˆç»“æœè½®è¯¢æ”¶æ•›",  # descriptionå‚æ•°
            )
        elif final_status in (TaskStatus.FAILED, "failed"):
            sync_update_task_status(
                task_id, TaskStatus.FAILED, {"completed_at": datetime.utcnow()}
            )
        else:
            # ä¸æ˜çŠ¶æ€ï¼Œä¿æŒå½“å‰çŠ¶æ€ï¼Œä»…å†™å…¥ç»“æœ
            logger.warning(f"æœªçŸ¥çš„æœ€ç»ˆçŠ¶æ€: {final_status}, ä¿æŒå½“å‰æ•°æ®åº“çŠ¶æ€")

        # å†™å…¥è¯¦ç»†ç»“æœ
        if result:
            sync_update_task_with_results(task_id, result)

        db_update_duration = (datetime.utcnow() - db_update_start).total_seconds()
        total_task_duration = (datetime.utcnow() - task_start_time).total_seconds()

        logger.info(
            f"âœ… Celeryä»»åŠ¡å®Œæˆ - ä»»åŠ¡ID: {task_id}\n"
            f"  â€¢ æ€»è€—æ—¶: {total_task_duration:.2f}s\n"
            f"  â€¢ å¤„ç†å™¨è€—æ—¶: {processing_duration:.2f}s\n"
            f"  â€¢ æ•°æ®åº“æ›´æ–°è€—æ—¶: {db_update_duration:.3f}s\n"
            f"  â€¢ ç»“æœæ•°æ®: {len(str(result)) if result else 0} bytes\n"
            f"  â€¢ Worker: {self.request.hostname}\n"
            f"  â€¢ Celeryä»»åŠ¡ID: {self.request.id}"
        )
        return result

    except Exception as exc:
        task_duration = (datetime.utcnow() - task_start_time).total_seconds()
        error_msg = str(exc)
        error_traceback = traceback.format_exc()

        logger.error(
            f"âŒ Celeryä»»åŠ¡å¤±è´¥ - ä»»åŠ¡ID: {task_id}\n"
            f"  â€¢ æ€»è€—æ—¶: {task_duration:.2f}s\n"
            f"  â€¢ é”™è¯¯ä¿¡æ¯: {error_msg}\n"
            f"  â€¢ é”™è¯¯ç±»å‹: {type(exc).__name__}\n"
            f"  â€¢ Worker: {self.request.hostname}\n"
            f"  â€¢ Celeryä»»åŠ¡ID: {self.request.id}"
        )
        logger.debug(f"è¯¦ç»†é”™è¯¯å †æ ˆ: {error_traceback}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        self.update_state(
            state="FAILURE",
            meta={
                "error": error_msg,
                "traceback": error_traceback,
                "worker_name": self.request.hostname,
            },
        )

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        try:
            db_update_start = datetime.utcnow()
            sync_update_task_status(
                task_id,
                TaskStatus.FAILED,
                {
                    "error_message": error_msg,
                    "error_traceback": error_traceback,
                    "error_type": type(exc).__name__,
                    "failed_duration": f"{task_duration:.2f}s",
                    "completed_at": datetime.utcnow(),
                },
            )
            db_update_duration = (datetime.utcnow() - db_update_start).total_seconds()
            logger.debug(f"æ•°æ®åº“é”™è¯¯çŠ¶æ€æ›´æ–°å®Œæˆ - è€—æ—¶: {db_update_duration:.3f}s")
        except Exception as db_error:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {db_error}")

        raise exc


@celery_app.task(
    bind=True,
    base=CallbackTask,
    queue="video_generation",
    autoretry_for=(Exception,),
    retry_kwargs={"max_retries": 2, "countdown": 30},
    time_limit=1800,  # 30åˆ†é’Ÿè¶…æ—¶
    soft_time_limit=1500,  # 25åˆ†é’Ÿè½¯è¶…æ—¶
)
@validate_task_exists
def process_video_generation(
    self,
    task_id: str,
    script_data: Dict[str, Any],
    workspace_dir: str,
    video_index: int = 0,
):
    """
    å¤„ç†è§†é¢‘ç”Ÿæˆä»»åŠ¡

    Args:
        task_id: ä»»åŠ¡ID
        script_data: è„šæœ¬æ•°æ®
        workspace_dir: å·¥ä½œç›®å½•
        video_index: è§†é¢‘ç´¢å¼•ï¼ˆç”¨äºå¤šè§†é¢‘ç”Ÿæˆï¼‰
    """
    try:
        logger.info(
            f"Starting video generation for task {task_id}, video index {video_index}"
        )

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state="PROCESSING",
            meta={
                "progress": 75,
                "stage": "video_generation",
                "message": f"Generating video {video_index + 1}...",
                "worker_name": self.request.hostname,
            },
        )

        # ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬çš„è§†é¢‘ç”Ÿæˆå™¨
        from services.sync_video_generator import SyncVideoGenerator

        generator = SyncVideoGenerator()

        # æ‰§è¡Œè§†é¢‘ç”Ÿæˆ
        result = generator.generate_video(
            task_id=task_id,
            script_data=script_data,
            workspace_dir=workspace_dir,
            video_index=video_index,
        )

        logger.info(
            f"Video generation completed for task {task_id}, video {video_index}"
        )
        return result

    except Exception as exc:
        error_msg = str(exc)
        error_traceback = traceback.format_exc()

        logger.error(f"Video generation task {task_id} failed: {error_msg}")
        logger.error(f"Traceback: {error_traceback}")

        self.update_state(
            state="FAILURE",
            meta={
                "error": error_msg,
                "traceback": error_traceback,
                "worker_name": self.request.hostname,
            },
        )

        raise exc


@celery_app.task(bind=True, queue="maintenance")
def cleanup_expired_tasks(self):
    """æ¸…ç†è¿‡æœŸä»»åŠ¡çš„å®šæœŸç»´æŠ¤ä»»åŠ¡"""
    try:
        logger.info("Starting cleanup of expired tasks")

        from utils.redis_cleanup import cleanup_redis_tasks

        # æ‰§è¡ŒRedisä»»åŠ¡æ¸…ç†
        cleanup_result = cleanup_redis_tasks(force=False, max_age_hours=24)
        
        logger.info(f"Redisæ¸…ç†å®Œæˆ: {cleanup_result}")

        # æ¸…ç†æ•°æ®åº“è¿æ¥æ± ï¼ˆå¯é€‰ï¼‰
        # close_sync_connection_pool()

        return {
            "status": "completed", 
            "message": "Cleanup tasks completed",
            "redis_cleanup": cleanup_result
        }

    except Exception as exc:
        logger.error(f"Cleanup task failed: {exc}")
        raise


@celery_app.task(bind=True, queue="monitoring")
def health_check(self):
    """å¥åº·æ£€æŸ¥ä»»åŠ¡"""
    try:
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥ï¼ˆä½¿ç”¨åŒæ­¥æ–¹æ³•ï¼‰
        db_health = sync_check_database_health()
        db_status = db_health.get("status", "unhealthy")

        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "database": db_status,
            "worker": self.request.hostname,
        }

    except Exception as exc:
        logger.error(f"Health check failed: {exc}")
        return {
            "status": "unhealthy",
            "error": str(exc),
            "timestamp": datetime.utcnow().isoformat(),
        }
