#!/usr/bin/env python3
"""
TypeScripté£æ ¼çš„Pythonç±»å‹æ£€æŸ¥åˆ†æå™¨
åˆ†æé¡¹ç›®çš„ç±»å‹æ³¨è§£è¦†ç›–ç‡å’Œç±»å‹å®‰å…¨æ€§
"""
from __future__ import annotations

import ast
import json
import os
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple


@dataclass
class TypeCoverageStats:
    """ç±»å‹è¦†ç›–ç‡ç»Ÿè®¡"""

    total_functions: int = 0
    typed_functions: int = 0
    total_methods: int = 0
    typed_methods: int = 0
    total_classes: int = 0
    typed_classes: int = 0
    total_variables: int = 0
    typed_variables: int = 0

    @property
    def function_coverage(self) -> float:
        return (
            (self.typed_functions / self.total_functions * 100)
            if self.total_functions > 0
            else 0.0
        )

    @property
    def method_coverage(self) -> float:
        return (
            (self.typed_methods / self.total_methods * 100)
            if self.total_methods > 0
            else 0.0
        )

    @property
    def overall_coverage(self) -> float:
        total_items = self.total_functions + self.total_methods
        typed_items = self.typed_functions + self.typed_methods
        return (typed_items / total_items * 100) if total_items > 0 else 0.0


@dataclass
class FileAnalysis:
    """æ–‡ä»¶åˆ†æç»“æœ"""

    file_path: str
    stats: TypeCoverageStats
    issues: List[str]
    suggestions: List[str]


class TypeAnalyzer(ast.NodeVisitor):
    """TypeScripté£æ ¼çš„ç±»å‹åˆ†æå™¨"""

    def __init__(self, file_path: str) -> None:
        self.file_path = file_path
        self.stats = TypeCoverageStats()
        self.issues: List[str] = []
        self.suggestions: List[str] = []
        self.current_class: Optional[str] = None

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        """åˆ†æå‡½æ•°å®šä¹‰"""
        if self.current_class:
            self.stats.total_methods += 1
            if node.returns:
                self.stats.typed_methods += 1
            else:
                self.issues.append(
                    f"æ–¹æ³• {self.current_class}.{node.name} ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£"
                )
                self.suggestions.append(
                    f"ä¸º {self.current_class}.{node.name} æ·»åŠ è¿”å›ç±»å‹: -> ReturnType"
                )
        else:
            self.stats.total_functions += 1
            if node.returns:
                self.stats.typed_functions += 1
            else:
                self.issues.append(f"å‡½æ•° {node.name} ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£")
                self.suggestions.append(f"ä¸º {node.name} æ·»åŠ è¿”å›ç±»å‹: -> ReturnType")

        # æ£€æŸ¥å‚æ•°ç±»å‹æ³¨è§£
        for arg in node.args.args:
            if not arg.annotation and arg.arg != "self":
                self.issues.append(f"å‚æ•° {arg.arg} åœ¨ {node.name} ä¸­ç¼ºå°‘ç±»å‹æ³¨è§£")

        self.generic_visit(node)

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:
        """åˆ†æå¼‚æ­¥å‡½æ•°å®šä¹‰"""
        if self.current_class:
            self.stats.total_methods += 1
            if node.returns:
                self.stats.typed_methods += 1
            else:
                self.issues.append(
                    f"å¼‚æ­¥æ–¹æ³• {self.current_class}.{node.name} ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£"
                )
                self.suggestions.append(
                    f"ä¸º {self.current_class}.{node.name} æ·»åŠ è¿”å›ç±»å‹: -> Awaitable[ReturnType]"
                )
        else:
            self.stats.total_functions += 1
            if node.returns:
                self.stats.typed_functions += 1
            else:
                self.issues.append(f"å¼‚æ­¥å‡½æ•° {node.name} ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£")
                self.suggestions.append(
                    f"ä¸º {node.name} æ·»åŠ è¿”å›ç±»å‹: -> Awaitable[ReturnType]"
                )

        # æ£€æŸ¥å‚æ•°ç±»å‹æ³¨è§£
        for arg in node.args.args:
            if not arg.annotation and arg.arg != "self":
                self.issues.append(f"å‚æ•° {arg.arg} åœ¨å¼‚æ­¥ {node.name} ä¸­ç¼ºå°‘ç±»å‹æ³¨è§£")

        self.generic_visit(node)

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        """åˆ†æç±»å®šä¹‰"""
        self.stats.total_classes += 1
        old_class = self.current_class
        self.current_class = node.name

        # æ£€æŸ¥æ˜¯å¦æœ‰ç±»å‹æ³¨è§£çš„å±æ€§
        has_typed_attrs = False
        for item in node.body:
            if isinstance(item, ast.AnnAssign):
                has_typed_attrs = True
                break

        if has_typed_attrs:
            self.stats.typed_classes += 1
        else:
            self.suggestions.append(f"è€ƒè™‘ä¸ºç±» {node.name} çš„å±æ€§æ·»åŠ ç±»å‹æ³¨è§£")

        self.generic_visit(node)
        self.current_class = old_class

    def visit_AnnAssign(self, node: ast.AnnAssign) -> None:
        """åˆ†æç±»å‹æ³¨è§£çš„èµ‹å€¼"""
        self.stats.typed_variables += 1
        self.generic_visit(node)

    def visit_Assign(self, node: ast.Assign) -> None:
        """åˆ†ææ™®é€šèµ‹å€¼"""
        self.stats.total_variables += 1
        self.generic_visit(node)


class ProjectTypeAnalyzer:
    """é¡¹ç›®çº§åˆ«çš„ç±»å‹åˆ†æå™¨"""

    def __init__(self, project_root: str) -> None:
        self.project_root = Path(project_root)
        self.file_analyses: List[FileAnalysis] = []

    def analyze_file(self, file_path: Path) -> FileAnalysis:
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                source = f.read()

            tree = ast.parse(source)
            analyzer = TypeAnalyzer(str(file_path))
            analyzer.visit(tree)

            return FileAnalysis(
                file_path=str(file_path.relative_to(self.project_root)),
                stats=analyzer.stats,
                issues=analyzer.issues,
                suggestions=analyzer.suggestions,
            )
        except Exception as e:
            return FileAnalysis(
                file_path=str(file_path.relative_to(self.project_root)),
                stats=TypeCoverageStats(),
                issues=[f"è§£æé”™è¯¯: {str(e)}"],
                suggestions=[],
            )

    def analyze_project(
        self, exclude_patterns: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        if exclude_patterns is None:
            exclude_patterns = [
                "venv",
                ".venv",
                "__pycache__",
                ".git",
                "node_modules",
                "alembic/versions",
                "logs",
                "workspace",
                "test",
                "tests",
            ]

        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            # æ’é™¤æŒ‡å®šç›®å½•
            dirs[:] = [
                d for d in dirs if not any(pattern in d for pattern in exclude_patterns)
            ]

            for file in files:
                if file.endswith(".py") and not file.startswith("."):
                    file_path = Path(root) / file
                    python_files.append(file_path)

        # åˆ†ææ‰€æœ‰æ–‡ä»¶
        self.file_analyses = []
        for file_path in python_files:
            analysis = self.analyze_file(file_path)
            self.file_analyses.append(analysis)

        return self.generate_report()

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç±»å‹æ£€æŸ¥æŠ¥å‘Š"""
        total_stats = TypeCoverageStats()
        high_priority_issues = []
        improvement_suggestions = []

        # èšåˆç»Ÿè®¡
        for analysis in self.file_analyses:
            stats = analysis.stats
            total_stats.total_functions += stats.total_functions
            total_stats.typed_functions += stats.typed_functions
            total_stats.total_methods += stats.total_methods
            total_stats.typed_methods += stats.typed_methods
            total_stats.total_classes += stats.total_classes
            total_stats.typed_classes += stats.typed_classes
            total_stats.total_variables += stats.total_variables
            total_stats.typed_variables += stats.typed_variables

            # æ”¶é›†é—®é¢˜å’Œå»ºè®®
            if analysis.issues:
                high_priority_issues.extend(
                    [
                        f"{analysis.file_path}: {issue}"
                        for issue in analysis.issues[:3]  # é™åˆ¶æ¯ä¸ªæ–‡ä»¶æœ€å¤š3ä¸ªé—®é¢˜
                    ]
                )

            if analysis.suggestions:
                improvement_suggestions.extend(
                    [
                        f"{analysis.file_path}: {suggestion}"
                        for suggestion in analysis.suggestions[
                            :2
                        ]  # é™åˆ¶æ¯ä¸ªæ–‡ä»¶æœ€å¤š2ä¸ªå»ºè®®
                    ]
                )

        # æŒ‰è¦†ç›–ç‡æ’åºæ–‡ä»¶
        files_by_coverage = sorted(
            [
                (analysis.file_path, analysis.stats.overall_coverage)
                for analysis in self.file_analyses
            ],
            key=lambda x: x[1],
        )

        return {
            "analysis_timestamp": datetime.now().isoformat(),
            "overall_statistics": {
                "total_files_analyzed": len(self.file_analyses),
                "function_coverage": round(total_stats.function_coverage, 2),
                "method_coverage": round(total_stats.method_coverage, 2),
                "overall_coverage": round(total_stats.overall_coverage, 2),
                "total_functions": total_stats.total_functions,
                "typed_functions": total_stats.typed_functions,
                "total_methods": total_stats.total_methods,
                "typed_methods": total_stats.typed_methods,
                "total_classes": total_stats.total_classes,
                "typed_classes": total_stats.typed_classes,
            },
            "coverage_by_category": {
                "excellent": [f for f, c in files_by_coverage if c >= 90],
                "good": [f for f, c in files_by_coverage if 70 <= c < 90],
                "needs_improvement": [f for f, c in files_by_coverage if 50 <= c < 70],
                "poor": [f for f, c in files_by_coverage if c < 50],
            },
            "priority_improvements": {
                "high_priority_issues": high_priority_issues[
                    :20
                ],  # æœ€å¤š20ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜
                "improvement_suggestions": improvement_suggestions[
                    :15
                ],  # æœ€å¤š15ä¸ªæ”¹è¿›å»ºè®®
                "recommended_next_steps": self._generate_recommendations(total_stats),
            },
            "file_details": [
                {
                    "file": analysis.file_path,
                    "coverage": round(analysis.stats.overall_coverage, 2),
                    "functions": f"{analysis.stats.typed_functions}/{analysis.stats.total_functions}",
                    "methods": f"{analysis.stats.typed_methods}/{analysis.stats.total_methods}",
                    "issues_count": len(analysis.issues),
                }
                for analysis in sorted(
                    self.file_analyses, key=lambda x: x.stats.overall_coverage
                )
            ],
        }

    def _generate_recommendations(self, stats: TypeCoverageStats) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        if stats.overall_coverage < 50:
            recommendations.append("ç«‹å³å¼€å§‹ä¸ºæ ¸å¿ƒå‡½æ•°æ·»åŠ è¿”å›ç±»å‹æ³¨è§£")
            recommendations.append("ä¼˜å…ˆå¤„ç†å…¬å…±APIå’Œå…³é”®ä¸šåŠ¡é€»è¾‘å‡½æ•°")
        elif stats.overall_coverage < 80:
            recommendations.append("ç»§ç»­å®Œå–„å‰©ä½™å‡½æ•°çš„ç±»å‹æ³¨è§£")
            recommendations.append("è€ƒè™‘å¯ç”¨mypyçš„strictæ¨¡å¼")
        else:
            recommendations.append("ç±»å‹è¦†ç›–ç‡è‰¯å¥½ï¼Œè€ƒè™‘å¯ç”¨æ›´ä¸¥æ ¼çš„ç±»å‹æ£€æŸ¥")
            recommendations.append("æ·»åŠ ç±»å±æ€§å’Œå¤æ‚æ•°æ®ç»“æ„çš„ç±»å‹æ³¨è§£")

        if stats.function_coverage > stats.method_coverage:
            recommendations.append("é‡ç‚¹æ”¹è¿›ç±»æ–¹æ³•çš„ç±»å‹æ³¨è§£è¦†ç›–ç‡")

        recommendations.extend(
            [
                "è®¾ç½®pre-commit hookæ‰§è¡Œç±»å‹æ£€æŸ¥",
                "åœ¨CI/CDæµæ°´çº¿ä¸­é›†æˆmypyæ£€æŸ¥",
                "è€ƒè™‘ä½¿ç”¨dataclassesæˆ–Pydanticè¿›è¡Œæ•°æ®å»ºæ¨¡",
            ]
        )

        return recommendations


def main() -> None:
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        project_root = sys.argv[1]
    else:
        project_root = os.getcwd()

    print("ğŸ” å¼€å§‹TypeScripté£æ ¼çš„Pythonç±»å‹åˆ†æ...")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")

    analyzer = ProjectTypeAnalyzer(project_root)
    report = analyzer.analyze_project()

    # è¾“å‡ºæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š TextLoom é¡¹ç›®ç±»å‹æ³¨è§£åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    stats = report["overall_statistics"]
    print(f"ğŸ“ˆ æ€»ä½“è¦†ç›–ç‡: {stats['overall_coverage']}%")
    print(
        f"ğŸ”§ å‡½æ•°è¦†ç›–ç‡: {stats['function_coverage']}% ({stats['typed_functions']}/{stats['total_functions']})"
    )
    print(
        f"âš™ï¸  æ–¹æ³•è¦†ç›–ç‡: {stats['method_coverage']}% ({stats['typed_methods']}/{stats['total_methods']})"
    )
    print(f"ğŸ“ åˆ†ææ–‡ä»¶æ•°: {stats['total_files_analyzed']}")

    print(f"\nğŸ“Š è¦†ç›–ç‡åˆ†ç±»:")
    categories = report["coverage_by_category"]
    print(f"  ğŸŸ¢ ä¼˜ç§€ (â‰¥90%): {len(categories['excellent'])} ä¸ªæ–‡ä»¶")
    print(f"  ğŸŸ¡ è‰¯å¥½ (70-89%): {len(categories['good'])} ä¸ªæ–‡ä»¶")
    print(f"  ğŸŸ  éœ€æ”¹è¿› (50-69%): {len(categories['needs_improvement'])} ä¸ªæ–‡ä»¶")
    print(f"  ğŸ”´ è¾ƒå·® (<50%): {len(categories['poor'])} ä¸ªæ–‡ä»¶")

    if categories["poor"]:
        print(f"\nâš ï¸  éœ€è¦ä¼˜å…ˆæ”¹è¿›çš„æ–‡ä»¶:")
        for file in categories["poor"][:5]:
            print(f"   - {file}")

    print(f"\nğŸ¯ æ”¹è¿›å»ºè®®:")
    for i, suggestion in enumerate(
        report["priority_improvements"]["recommended_next_steps"][:5], 1
    ):
        print(f"   {i}. {suggestion}")

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = (
        f"type_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("âœ… åˆ†æå®Œæˆ!")


if __name__ == "__main__":
    main()
