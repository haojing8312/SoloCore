#!/usr/bin/env python3
"""
æ•°æ®åº“è¿æ¥æ± é…ç½®æµ‹è¯•è„šæœ¬
éªŒè¯é…ç½®æ›´æ”¹æ˜¯å¦æ­£ç¡®ï¼Œå¹¶æµ‹è¯•åœ¨è´Ÿè½½ä¸‹çš„è¡¨ç°
"""

import asyncio
import logging
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from typing import Any, Dict, List

import asyncpg
import psycopg2

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import settings
from models.celery_db import get_sync_connection_pool, sync_check_database_health
from models.db_connection import (
    check_connection_pool_health,
    get_db_session,
    get_engine,
)

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class DatabaseConfigTester:
    """æ•°æ®åº“é…ç½®æµ‹è¯•å™¨"""

    def __init__(self):
        self.results: Dict[str, Any] = {
            "config_verification": {},
            "connection_tests": {},
            "load_tests": {},
            "recommendations": [],
        }

    def verify_config_consistency(self) -> Dict[str, Any]:
        """éªŒè¯é…ç½®ä¸€è‡´æ€§"""
        logger.info("ğŸ” éªŒè¯æ•°æ®åº“è¿æ¥æ± é…ç½®ä¸€è‡´æ€§...")

        config_issues = []
        config_info = {
            "async_pool": {
                "pool_size": settings.database_pool_size,
                "max_overflow": settings.database_max_overflow,
                "pool_recycle": settings.database_pool_recycle,
                "pool_timeout": settings.database_pool_timeout,
                "pool_pre_ping": settings.database_pool_pre_ping,
            },
            "celery_pool": {
                "pool_size": settings.celery_database_pool_size,
                "max_overflow": settings.celery_database_max_overflow,
                "min_connections": settings.celery_database_min_connections,
                "pool_recycle": settings.database_pool_recycle,
            },
        }

        # æ£€æŸ¥é…ç½®åˆç†æ€§
        if settings.database_max_overflow == 0:
            config_issues.append("å¼‚æ­¥è¿æ¥æ± max_overflowä¸º0ï¼Œå¯èƒ½å¯¼è‡´è¿æ¥é¥¥é¥¿")

        if settings.database_pool_size < 5:
            config_issues.append("å¼‚æ­¥è¿æ¥æ± æ± å¤§å°å¯èƒ½è¿‡å°")

        if (
            settings.celery_database_pool_size
            < settings.celery_database_min_connections
        ):
            config_issues.append("Celeryè¿æ¥æ± æœ€å¤§è¿æ¥æ•°å°äºæœ€å°è¿æ¥æ•°")

        # æ£€æŸ¥æ€»è¿æ¥æ•°æ˜¯å¦åˆç†
        max_total_connections = (
            settings.database_pool_size
            + settings.database_max_overflow
            + settings.celery_database_pool_size
            + settings.celery_database_max_overflow
        )

        if max_total_connections > 50:
            config_issues.append(f"æ€»æœ€å¤§è¿æ¥æ•°({max_total_connections})å¯èƒ½è¿‡é«˜")

        result = {
            "config_info": config_info,
            "issues": config_issues,
            "max_total_connections": max_total_connections,
            "status": "OK" if not config_issues else "WARNING",
        }

        self.results["config_verification"] = result
        return result

    async def test_async_connection_pool(self) -> Dict[str, Any]:
        """æµ‹è¯•å¼‚æ­¥è¿æ¥æ± """
        logger.info("ğŸ§ª æµ‹è¯•å¼‚æ­¥æ•°æ®åº“è¿æ¥æ± ...")

        test_results = {
            "basic_connection": False,
            "pool_health": {},
            "concurrent_connections": 0,
            "response_times": [],
        }

        try:
            # åŸºç¡€è¿æ¥æµ‹è¯•
            start_time = time.time()
            async with get_db_session() as session:
                result = await session.execute(text("SELECT 1 as test"))
                test_value = result.scalar()
                if test_value == 1:
                    test_results["basic_connection"] = True

            test_results["response_times"].append(time.time() - start_time)

            # è¿æ¥æ± å¥åº·æ£€æŸ¥
            pool_health = await check_connection_pool_health()
            test_results["pool_health"] = pool_health

            # å¹¶å‘è¿æ¥æµ‹è¯•
            concurrent_tasks = []
            for i in range(5):  # åˆ›å»º5ä¸ªå¹¶å‘è¿æ¥
                concurrent_tasks.append(self._async_db_task(i))

            concurrent_results = await asyncio.gather(
                *concurrent_tasks, return_exceptions=True
            )
            successful_connections = sum(
                1 for r in concurrent_results if not isinstance(r, Exception)
            )
            test_results["concurrent_connections"] = successful_connections

            logger.info(f"å¼‚æ­¥è¿æ¥æ± æµ‹è¯•å®Œæˆ: {successful_connections}/5 ä¸ªè¿æ¥æˆåŠŸ")

        except Exception as e:
            logger.error(f"å¼‚æ­¥è¿æ¥æ± æµ‹è¯•å¤±è´¥: {e}")
            test_results["error"] = str(e)

        self.results["connection_tests"]["async"] = test_results
        return test_results

    async def _async_db_task(self, task_id: int) -> bool:
        """å¼‚æ­¥æ•°æ®åº“ä»»åŠ¡"""
        try:
            async with get_db_session() as session:
                # æ¨¡æ‹Ÿä¸€äº›æ•°æ®åº“æ“ä½œ
                await asyncio.sleep(0.1)
                result = await session.execute(text(f"SELECT {task_id} as task_id"))
                return result.scalar() == task_id
        except Exception as e:
            logger.warning(f"å¼‚æ­¥ä»»åŠ¡{task_id}å¤±è´¥: {e}")
            return False

    def test_sync_connection_pool(self) -> Dict[str, Any]:
        """æµ‹è¯•åŒæ­¥è¿æ¥æ± """
        logger.info("ğŸ§ª æµ‹è¯•åŒæ­¥æ•°æ®åº“è¿æ¥æ± (Celery)...")

        test_results = {
            "basic_connection": False,
            "health_check": {},
            "concurrent_connections": 0,
            "response_times": [],
        }

        try:
            # åŸºç¡€å¥åº·æ£€æŸ¥
            start_time = time.time()
            health_status = sync_check_database_health()
            test_results["health_check"] = health_status
            test_results["response_times"].append(time.time() - start_time)

            if health_status.get("status") == "healthy":
                test_results["basic_connection"] = True

            # å¹¶å‘è¿æ¥æµ‹è¯•
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = [executor.submit(self._sync_db_task, i) for i in range(3)]
                successful_connections = sum(
                    1 for future in as_completed(futures) if future.result()
                )
                test_results["concurrent_connections"] = successful_connections

            logger.info(f"åŒæ­¥è¿æ¥æ± æµ‹è¯•å®Œæˆ: {successful_connections}/3 ä¸ªè¿æ¥æˆåŠŸ")

        except Exception as e:
            logger.error(f"åŒæ­¥è¿æ¥æ± æµ‹è¯•å¤±è´¥: {e}")
            test_results["error"] = str(e)

        self.results["connection_tests"]["sync"] = test_results
        return test_results

    def _sync_db_task(self, task_id: int) -> bool:
        """åŒæ­¥æ•°æ®åº“ä»»åŠ¡"""
        try:
            from models.celery_db import get_sync_db_connection

            with get_sync_db_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute(f"SELECT {task_id} as task_id")
                    result = cursor.fetchone()
                    return result[0] == task_id
        except Exception as e:
            logger.warning(f"åŒæ­¥ä»»åŠ¡{task_id}å¤±è´¥: {e}")
            return False

    async def run_load_test(self, duration_seconds: int = 30) -> Dict[str, Any]:
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        logger.info(f"ğŸš€ å¼€å§‹{duration_seconds}ç§’è´Ÿè½½æµ‹è¯•...")

        start_time = time.time()
        end_time = start_time + duration_seconds

        async_tasks = []
        sync_tasks = []
        async_success_count = 0
        sync_success_count = 0
        error_count = 0

        # å¼‚æ­¥ä»»åŠ¡è´Ÿè½½æµ‹è¯•
        async def async_load_worker():
            nonlocal async_success_count, error_count
            while time.time() < end_time:
                try:
                    success = await self._async_db_task(1)
                    if success:
                        async_success_count += 1
                    await asyncio.sleep(0.1)  # 100msé—´éš”
                except Exception as e:
                    error_count += 1
                    logger.warning(f"è´Ÿè½½æµ‹è¯•å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {e}")

        # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        for i in range(3):
            async_tasks.append(asyncio.create_task(async_load_worker()))

        # åŒæ­¥ä»»åŠ¡è´Ÿè½½æµ‹è¯•(åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ)
        def sync_load_worker():
            nonlocal sync_success_count, error_count
            while time.time() < end_time:
                try:
                    success = self._sync_db_task(1)
                    if success:
                        sync_success_count += 1
                    time.sleep(0.05)  # ä¼˜åŒ–ï¼šå‡å°‘è´Ÿè½½æµ‹è¯•é—´éš”åˆ°50ms
                except Exception as e:
                    error_count += 1
                    logger.warning(f"è´Ÿè½½æµ‹è¯•åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")

        # å¯åŠ¨åŒæ­¥ä»»åŠ¡
        with ThreadPoolExecutor(max_workers=2) as executor:
            sync_futures = [executor.submit(sync_load_worker) for _ in range(2)]

            # ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
            await asyncio.gather(*async_tasks, return_exceptions=True)

            # ç­‰å¾…åŒæ­¥ä»»åŠ¡å®Œæˆ
            for future in as_completed(sync_futures, timeout=duration_seconds + 5):
                try:
                    future.result()
                except Exception as e:
                    logger.error(f"åŒæ­¥è´Ÿè½½æµ‹è¯•ä»»åŠ¡å¼‚å¸¸: {e}")

        total_operations = async_success_count + sync_success_count
        ops_per_second = (
            total_operations / duration_seconds if duration_seconds > 0 else 0
        )

        load_test_results = {
            "duration_seconds": duration_seconds,
            "async_operations": async_success_count,
            "sync_operations": sync_success_count,
            "total_operations": total_operations,
            "errors": error_count,
            "ops_per_second": round(ops_per_second, 2),
            "success_rate": (
                round((total_operations / (total_operations + error_count)) * 100, 2)
                if (total_operations + error_count) > 0
                else 0
            ),
        }

        logger.info(
            f"è´Ÿè½½æµ‹è¯•å®Œæˆ: {total_operations}æ¬¡æ“ä½œ, {ops_per_second:.2f} ops/sec, é”™è¯¯: {error_count}"
        )

        self.results["load_tests"] = load_test_results
        return load_test_results

    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆé…ç½®å»ºè®®"""
        recommendations = []

        # åŸºäºé…ç½®éªŒè¯ç»“æœ
        config_result = self.results.get("config_verification", {})
        if config_result.get("issues"):
            recommendations.extend(
                [
                    "é…ç½®é—®é¢˜éœ€è¦ä¿®å¤:",
                    *[f"  â€¢ {issue}" for issue in config_result["issues"]],
                ]
            )

        # åŸºäºè¿æ¥æµ‹è¯•ç»“æœ
        async_test = self.results.get("connection_tests", {}).get("async", {})
        sync_test = self.results.get("connection_tests", {}).get("sync", {})

        if not async_test.get("basic_connection"):
            recommendations.append("å¼‚æ­¥è¿æ¥æ± è¿æ¥å¤±è´¥ï¼Œæ£€æŸ¥æ•°æ®åº“é…ç½®å’Œç½‘ç»œ")

        if not sync_test.get("basic_connection"):
            recommendations.append("åŒæ­¥è¿æ¥æ± è¿æ¥å¤±è´¥ï¼Œæ£€æŸ¥Celeryæ•°æ®åº“é…ç½®")

        # åŸºäºè´Ÿè½½æµ‹è¯•ç»“æœ
        load_test = self.results.get("load_tests", {})
        if load_test.get("success_rate", 100) < 95:
            recommendations.append(
                f"è´Ÿè½½æµ‹è¯•æˆåŠŸç‡({load_test.get('success_rate')}%)è¿‡ä½ï¼Œè€ƒè™‘å¢åŠ è¿æ¥æ± å¤§å°"
            )

        if load_test.get("ops_per_second", 0) < 10:
            recommendations.append("æ•°æ®åº“æ“ä½œæ€§èƒ½è¾ƒä½ï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–å¢åŠ è¿æ¥æ± å¤§å°")

        # é€šç”¨å»ºè®®
        recommendations.extend(
            [
                "å®šæœŸç›‘æ§è¿æ¥æ± ä½¿ç”¨æƒ…å†µ",
                "è®¾ç½®è¿æ¥æ± å‘Šè­¦é˜ˆå€¼",
                "è€ƒè™‘ä½¿ç”¨è¿æ¥æ± ç®¡ç†å·¥å…·(å¦‚pgbouncer)è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–",
            ]
        )

        self.results["recommendations"] = recommendations
        return recommendations

    def print_test_report(self):
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ æ•°æ®åº“è¿æ¥æ± é…ç½®æµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)
        print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # é…ç½®éªŒè¯ç»“æœ
        config_result = self.results.get("config_verification", {})
        print(f"\nğŸ“Š é…ç½®éªŒè¯: {config_result.get('status', 'UNKNOWN')}")
        print(f"   æœ€å¤§æ€»è¿æ¥æ•°: {config_result.get('max_total_connections', 'N/A')}")
        if config_result.get("issues"):
            print("   é…ç½®é—®é¢˜:")
            for issue in config_result["issues"]:
                print(f"     âš ï¸  {issue}")

        # è¿æ¥æµ‹è¯•ç»“æœ
        print(f"\nğŸ”— è¿æ¥æµ‹è¯•ç»“æœ:")
        async_test = self.results.get("connection_tests", {}).get("async", {})
        sync_test = self.results.get("connection_tests", {}).get("sync", {})

        async_status = "âœ…" if async_test.get("basic_connection") else "âŒ"
        sync_status = "âœ…" if sync_test.get("basic_connection") else "âŒ"

        print(
            f"   {async_status} å¼‚æ­¥è¿æ¥æ± : {async_test.get('concurrent_connections', 0)}/5 å¹¶å‘è¿æ¥æˆåŠŸ"
        )
        print(
            f"   {sync_status} åŒæ­¥è¿æ¥æ± : {sync_test.get('concurrent_connections', 0)}/3 å¹¶å‘è¿æ¥æˆåŠŸ"
        )

        # è´Ÿè½½æµ‹è¯•ç»“æœ
        load_test = self.results.get("load_tests", {})
        if load_test:
            print(f"\nğŸš€ è´Ÿè½½æµ‹è¯•ç»“æœ ({load_test.get('duration_seconds')}ç§’):")
            print(f"   æ€»æ“ä½œæ•°: {load_test.get('total_operations', 0)}")
            print(f"   æ“ä½œé€Ÿåº¦: {load_test.get('ops_per_second', 0)} ops/sec")
            print(f"   æˆåŠŸç‡: {load_test.get('success_rate', 0)}%")
            print(f"   é”™è¯¯æ•°: {load_test.get('errors', 0)}")

        # å»ºè®®
        recommendations = self.results.get("recommendations", [])
        if recommendations:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                if rec.startswith("  "):
                    print(f"     {rec}")
                else:
                    print(f"   â€¢ {rec}")

        print("\n" + "=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ•°æ®åº“è¿æ¥æ± é…ç½®æµ‹è¯•")
    parser.add_argument(
        "--load-test-duration", type=int, default=10, help="è´Ÿè½½æµ‹è¯•æ—¶é•¿(ç§’)"
    )
    parser.add_argument("--skip-load-test", action="store_true", help="è·³è¿‡è´Ÿè½½æµ‹è¯•")

    args = parser.parse_args()

    tester = DatabaseConfigTester()

    try:
        print("ğŸš€ å¼€å§‹æ•°æ®åº“è¿æ¥æ± é…ç½®æµ‹è¯•...")

        # 1. é…ç½®éªŒè¯
        tester.verify_config_consistency()

        # 2. è¿æ¥æµ‹è¯•
        await tester.test_async_connection_pool()
        tester.test_sync_connection_pool()

        # 3. è´Ÿè½½æµ‹è¯•(å¯é€‰)
        if not args.skip_load_test:
            await tester.run_load_test(args.load_test_duration)

        # 4. ç”Ÿæˆå»ºè®®
        tester.generate_recommendations()

        # 5. æ‰“å°æŠ¥å‘Š
        tester.print_test_report()

        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.exception("æµ‹è¯•å¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    # éœ€è¦å¯¼å…¥textä»¥æ”¯æŒSQLè¯­å¥
    from sqlalchemy import text

    asyncio.run(main())
