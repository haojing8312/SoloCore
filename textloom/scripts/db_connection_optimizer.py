from utils.enhanced_logging import (
    log_critical,
    log_debug,
    log_error,
    log_info,
    log_warning,
)

#!/usr/bin/env python3
"""
æ•°æ®åº“è¿æ¥æ± é…ç½®ä¼˜åŒ–è„šæœ¬
åˆ†æå½“å‰é…ç½®å¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import asyncio
import logging
import os
import sys
import time
from contextlib import asynccontextmanager
from dataclasses import dataclass
from typing import Any, Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import settings
from models.celery_db import get_sync_connection_pool
from models.db_connection import check_connection_pool_health, get_engine

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ConnectionPoolAnalysis:
    """è¿æ¥æ± åˆ†æç»“æœ"""

    service_name: str
    pool_size: int
    max_overflow: int
    current_connections: int
    available_connections: int
    max_possible_connections: int
    utilization_rate: float
    recommendations: List[str]


class DatabaseConnectionOptimizer:
    """æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.analyses: List[ConnectionPoolAnalysis] = []

    async def analyze_async_pool(self) -> ConnectionPoolAnalysis:
        """åˆ†æå¼‚æ­¥è¿æ¥æ± (FastAPI)"""
        try:
            pool_health = await check_connection_pool_health()

            recommendations = []

            # åˆ†æè¿æ¥æ± é…ç½®
            pool_size = pool_health.get("pool_size", 5)
            checked_out = pool_health.get("checked_out", 0)
            overflow = pool_health.get("overflow", 0)

            # è®¡ç®—åˆ©ç”¨ç‡
            utilization_rate = checked_out / max(pool_size, 1) * 100

            # ç”Ÿæˆå»ºè®®
            if utilization_rate > 80:
                recommendations.append("è¿æ¥æ± åˆ©ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ pool_size")

            if overflow > 0:
                recommendations.append(
                    f"å½“å‰æœ‰{overflow}ä¸ªæº¢å‡ºè¿æ¥ï¼Œè€ƒè™‘ä¼˜åŒ–æŸ¥è¯¢æˆ–å¢åŠ åŸºç¡€è¿æ¥æ± å¤§å°"
                )

            if not pool_health.get("is_healthy", False):
                recommendations.append("è¿æ¥æ± å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®")

            return ConnectionPoolAnalysis(
                service_name="FastAPI (Async)",
                pool_size=pool_size,
                max_overflow=10,  # ç¡¬ç¼–ç å€¼
                current_connections=checked_out,
                available_connections=pool_size - checked_out,
                max_possible_connections=pool_size + 10,
                utilization_rate=utilization_rate,
                recommendations=recommendations,
            )
        except Exception as e:
            logger.error(f"åˆ†æå¼‚æ­¥è¿æ¥æ± å¤±è´¥: {e}")
            return ConnectionPoolAnalysis(
                service_name="FastAPI (Async)",
                pool_size=0,
                max_overflow=0,
                current_connections=0,
                available_connections=0,
                max_possible_connections=0,
                utilization_rate=0,
                recommendations=[f"è¿æ¥æ± åˆ†æå¤±è´¥: {str(e)}"],
            )

    def analyze_sync_pool(self) -> ConnectionPoolAnalysis:
        """åˆ†æåŒæ­¥è¿æ¥æ± (Celery)"""
        recommendations = []

        try:
            # è·å–è¿æ¥æ± ä¿¡æ¯
            pool = get_sync_connection_pool()

            # ThreadedConnectionPool æ²¡æœ‰ç›´æ¥çš„ç»Ÿè®¡APIï¼Œä½¿ç”¨é…ç½®å€¼
            pool_size = 10  # maxconn from celery_db.py
            min_conn = 2  # minconn from celery_db.py

            recommendations.extend(
                [
                    "Celeryä½¿ç”¨ThreadedConnectionPoolï¼Œç»Ÿè®¡ä¿¡æ¯æœ‰é™",
                    "å»ºè®®ç›‘æ§è¿æ¥è·å–è¶…æ—¶æƒ…å†µ",
                    "è€ƒè™‘å°†è¿æ¥æ± é…ç½®ç§»åˆ°ç¯å¢ƒå˜é‡ä¸­ç»Ÿä¸€ç®¡ç†",
                ]
            )

            return ConnectionPoolAnalysis(
                service_name="Celery (Sync)",
                pool_size=pool_size,
                max_overflow=0,
                current_connections=0,  # æ— æ³•ç›´æ¥è·å–
                available_connections=0,  # æ— æ³•ç›´æ¥è·å–
                max_possible_connections=pool_size,
                utilization_rate=0,
                recommendations=recommendations,
            )
        except Exception as e:
            logger.error(f"åˆ†æåŒæ­¥è¿æ¥æ± å¤±è´¥: {e}")
            return ConnectionPoolAnalysis(
                service_name="Celery (Sync)",
                pool_size=0,
                max_overflow=0,
                current_connections=0,
                available_connections=0,
                max_possible_connections=0,
                utilization_rate=0,
                recommendations=[f"è¿æ¥æ± åˆ†æå¤±è´¥: {str(e)}"],
            )

    async def run_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        log_debug("ğŸ” å¼€å§‹æ•°æ®åº“è¿æ¥æ± åˆ†æ...")

        # åˆ†æå¼‚æ­¥è¿æ¥æ± 
        log_info("ğŸ“Š åˆ†æFastAPIå¼‚æ­¥è¿æ¥æ± ...")
        async_analysis = await self.analyze_async_pool()
        self.analyses.append(async_analysis)

        # åˆ†æåŒæ­¥è¿æ¥æ± 
        log_info("ğŸ“Š åˆ†æCeleryåŒæ­¥è¿æ¥æ± ...")
        sync_analysis = self.analyze_sync_pool()
        self.analyses.append(sync_analysis)

        # ç”Ÿæˆæ€»ä½“å»ºè®®
        overall_recommendations = self._generate_overall_recommendations()

        return {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "analyses": self.analyses,
            "overall_recommendations": overall_recommendations,
            "configuration_issues": self._detect_configuration_issues(),
            "optimization_suggestions": self._generate_optimization_suggestions(),
        }

    def _generate_overall_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ€»ä½“å»ºè®®"""
        recommendations = [
            "ç»Ÿä¸€è¿æ¥æ± é…ç½®ï¼Œé¿å…ç¡¬ç¼–ç å€¼ä¸config.pyé…ç½®ä¸ä¸€è‡´",
            "å®æ–½è¿æ¥æ± ç›‘æ§ï¼Œå®šæœŸæ£€æŸ¥è¿æ¥æ³„éœ²æƒ…å†µ",
            "è€ƒè™‘å¼•å…¥è¿æ¥æ± ç®¡ç†ä¸­é—´ä»¶(å¦‚pgbouncer)è¿›è¡Œè¿æ¥å¤ç”¨",
            "å»ºç«‹è¿æ¥æ± ä½¿ç”¨è§„èŒƒï¼Œç¡®ä¿è¿æ¥æ­£ç¡®é‡Šæ”¾",
            "è®¾ç½®è¿æ¥æ± å‘Šè­¦æœºåˆ¶ï¼Œåœ¨è¿æ¥æ•°æ¥è¿‘ä¸Šé™æ—¶åŠæ—¶é€šçŸ¥",
        ]
        return recommendations

    def _detect_configuration_issues(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹é…ç½®é—®é¢˜"""
        issues = []

        # æ£€æŸ¥é…ç½®ä¸ä¸€è‡´é—®é¢˜
        issues.append(
            {
                "type": "CONFIG_INCONSISTENCY",
                "severity": "HIGH",
                "description": "db_connection.pyä¸­ç¡¬ç¼–ç çš„è¿æ¥æ± é…ç½®ä¸config.pyä¸ä¸€è‡´",
                "current_config": {
                    "config.py": {
                        "pool_size": settings.database_pool_size,
                        "max_overflow": settings.database_max_overflow,
                    },
                    "db_connection.py": {"pool_size": 5, "max_overflow": 10},
                },
                "recommendation": "ä½¿ç”¨settingsé…ç½®æ›¿æ¢ç¡¬ç¼–ç å€¼",
            }
        )

        # æ£€æŸ¥é›¶æº¢å‡ºé…ç½®é£é™©
        if settings.database_max_overflow == 0:
            issues.append(
                {
                    "type": "ZERO_OVERFLOW_RISK",
                    "severity": "HIGH",
                    "description": "config.pyä¸­max_overflow=0å¯èƒ½å¯¼è‡´è¿æ¥é¥¥é¥¿",
                    "recommendation": "è®¾ç½®é€‚å½“çš„max_overflowå€¼(å»ºè®®5-10)",
                }
            )

        return issues

    def _generate_optimization_suggestions(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # åŸºäºç³»ç»Ÿæ¶æ„çš„å»ºè®®
        suggestions.append(
            {
                "category": "CONNECTION_POOLING",
                "priority": "HIGH",
                "title": "ç»Ÿä¸€è¿æ¥æ± é…ç½®ç®¡ç†",
                "description": "å°†æ‰€æœ‰è¿æ¥æ± é…ç½®ç»Ÿä¸€åˆ°ç¯å¢ƒå˜é‡ä¸­ç®¡ç†",
                "implementation": [
                    "ä¿®æ”¹db_connection.pyä½¿ç”¨settingsé…ç½®",
                    "ä¿®æ”¹celery_db.pyä½¿ç”¨settingsé…ç½®",
                    "æ·»åŠ è¿æ¥æ± é…ç½®éªŒè¯",
                ],
            }
        )

        suggestions.append(
            {
                "category": "MONITORING",
                "priority": "MEDIUM",
                "title": "è¿æ¥æ± ç›‘æ§å’Œå‘Šè­¦",
                "description": "å®æ–½è¿æ¥æ± çŠ¶æ€ç›‘æ§",
                "implementation": [
                    "æ·»åŠ è¿æ¥æ± æŒ‡æ ‡æ”¶é›†",
                    "è®¾ç½®è¿æ¥æ•°å‘Šè­¦é˜ˆå€¼",
                    "å®šæœŸæ£€æŸ¥è¿æ¥æ³„éœ²",
                ],
            }
        )

        suggestions.append(
            {
                "category": "PERFORMANCE",
                "priority": "MEDIUM",
                "title": "è¿æ¥æ± æ€§èƒ½è°ƒä¼˜",
                "description": "åŸºäºå®é™…è´Ÿè½½è°ƒæ•´è¿æ¥æ± å‚æ•°",
                "implementation": [
                    "ç›‘æ§è¿æ¥æ± åˆ©ç”¨ç‡",
                    "è°ƒæ•´pool_sizeå’Œmax_overflow",
                    "ä¼˜åŒ–é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢",
                ],
            }
        )

        return suggestions

    def print_analysis_report(self, analysis_result: Dict[str, Any]):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        log_info("\n" + "=" * 80)
        log_info("ğŸ“‹ æ•°æ®åº“è¿æ¥æ± åˆ†ææŠ¥å‘Š")
        log_info("=" * 80)
        log_info(f"â° åˆ†ææ—¶é—´: {analysis_result['timestamp']}")

        # æ‰“å°å„è¿æ¥æ± åˆ†æç»“æœ
        log_info("\nğŸ“Š è¿æ¥æ± çŠ¶æ€åˆ†æ:")
        for analysis in analysis_result["analyses"]:
            log_info(f"\nğŸ”¸ {analysis.service_name}")
            log_info(f"   æ± å¤§å°: {analysis.pool_size}")
            log_info(f"   æœ€å¤§æº¢å‡º: {analysis.max_overflow}")
            log_info(f"   å½“å‰è¿æ¥: {analysis.current_connections}")
            log_info(f"   å¯ç”¨è¿æ¥: {analysis.available_connections}")
            log_info(f"   æœ€å¤§å¯èƒ½è¿æ¥: {analysis.max_possible_connections}")
            log_info(f"   åˆ©ç”¨ç‡: {analysis.utilization_rate:.1f}%")

            if analysis.recommendations:
                log_info("   å»ºè®®:")
                for rec in analysis.recommendations:
                    log_info(f"     â€¢ {rec}")

        # æ‰“å°é…ç½®é—®é¢˜
        log_warning(
            f"\nâš ï¸  é…ç½®é—®é¢˜ ({len(analysis_result['configuration_issues'])}ä¸ª):"
        )
        for issue in analysis_result["configuration_issues"]:
            severity_icon = "ğŸ”´" if issue["severity"] == "HIGH" else "ğŸŸ¡"
            log_info(f"{severity_icon} {issue['type']}: {issue['description']}")
            log_info(f"   å»ºè®®: {issue['recommendation']}")

        # æ‰“å°ä¼˜åŒ–å»ºè®®
        log_info(
            f"\nğŸš€ ä¼˜åŒ–å»ºè®® ({len(analysis_result['optimization_suggestions'])}ä¸ª):"
        )
        for suggestion in analysis_result["optimization_suggestions"]:
            priority_icon = "ğŸ”¥" if suggestion["priority"] == "HIGH" else "â­"
            log_info(
                f"{priority_icon} {suggestion['title']} ({suggestion['category']})"
            )
            log_info(f"   {suggestion['description']}")

        # æ‰“å°æ€»ä½“å»ºè®®
        log_info(f"\nğŸ’¡ æ€»ä½“å»ºè®®:")
        for rec in analysis_result["overall_recommendations"]:
            log_info(f"   â€¢ {rec}")

        log_info("\n" + "=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    optimizer = DatabaseConnectionOptimizer()

    try:
        # è¿è¡Œåˆ†æ
        analysis_result = await optimizer.run_analysis()

        # æ‰“å°æŠ¥å‘Š
        optimizer.print_analysis_report(analysis_result)

        log_info("\nâœ… åˆ†æå®Œæˆï¼")
        log_error("ğŸ“ å»ºè®®æŸ¥çœ‹ç”Ÿæˆçš„ä¼˜åŒ–å»ºè®®å¹¶é€æ­¥å®æ–½æ”¹è¿›ã€‚")

    except Exception as e:
        log_error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.exception("åˆ†æå¤±è´¥")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
