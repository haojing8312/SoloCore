#!/usr/bin/env python3
"""
TextLoom æ•°æ®åº“ç®¡ç†è„šæœ¬
åŒ…å«æ•°æ®åº“åˆå§‹åŒ–ã€è¡¨åˆ›å»ºã€çŠ¶æ€æ£€æŸ¥å’ŒéªŒè¯åŠŸèƒ½
"""

import asyncio
import json
import logging
import uuid
from datetime import datetime

import asyncpg
import requests

from config import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def parse_database_url(url):
    """è§£ææ•°æ®åº“URL"""
    import re

    pattern = r"postgresql\+asyncpg://([^:]+):([^@]+)@([^:]+):(\d+)/([^?]+)"
    match = re.match(pattern, url)
    if match:
        return {
            "user": match.group(1),
            "password": match.group(2),
            "host": match.group(3),
            "port": int(match.group(4)),
            "database": match.group(5),
        }
    raise ValueError(f"æ— æ³•è§£ææ•°æ®åº“URL: {url}")


async def create_connection():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    db_config = parse_database_url(settings.database_url)
    return await asyncpg.connect(
        user=db_config["user"],
        password=db_config["password"],
        host=db_config["host"],
        port=db_config["port"],
        database=db_config["database"],
        server_settings={"search_path": "textloom_core, public"},
        statement_cache_size=0,  # ç¦ç”¨ prepared statementsï¼Œå…¼å®¹pgbouncer
    )


async def create_schema():
    """åˆ›å»ºschema"""
    try:
        logger.info("åˆ›å»º textloom_core schema...")
        conn = await create_connection()
        try:
            await conn.execute("CREATE SCHEMA IF NOT EXISTS textloom_core")
            logger.info("Schema åˆ›å»ºæˆåŠŸ")
        finally:
            await conn.close()
        return True
    except Exception as e:
        logger.error(f"åˆ›å»º schema å¤±è´¥: {e}")
        return False


async def create_tables():
    """åˆ›å»ºæ‰€æœ‰æ•°æ®åº“è¡¨"""
    try:
        logger.info("åˆ›å»ºæ•°æ®åº“è¡¨...")
        conn = await create_connection()
        try:
            # åˆ›å»ºè¡¨çš„SQLè¯­å¥
            sql_statements = [
                # è§†é¢‘é¡¹ç›®è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.video_projects (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    project_name VARCHAR(255) NOT NULL,
                    description TEXT,
                    project_type VARCHAR(50) NOT NULL DEFAULT 'video_generation',
                    status VARCHAR(50) NOT NULL DEFAULT 'created',
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    config JSONB
                )
                """,
                # ä»»åŠ¡è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.tasks (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    task_name VARCHAR(255) NOT NULL,
                    task_type VARCHAR(50) NOT NULL,
                    status VARCHAR(50) NOT NULL DEFAULT 'pending',
                    priority INTEGER NOT NULL DEFAULT 0,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    config JSONB,
                    result JSONB,
                    error_message TEXT
                )
                """,
                # åª’ä½“é¡¹ç›®è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.media_items (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    task_id UUID NOT NULL REFERENCES textloom_core.tasks(id),
                    file_path VARCHAR(500) NOT NULL,
                    file_type VARCHAR(50) NOT NULL,
                    file_size BIGINT,
                    duration REAL,
                    metadata JSONB,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # ç´ æåˆ†æè¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.material_analyses (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    task_id UUID NOT NULL REFERENCES textloom_core.tasks(id),
                    analysis_type VARCHAR(50) NOT NULL,
                    status VARCHAR(50) NOT NULL DEFAULT 'pending',
                    result JSONB,
                    confidence_score REAL,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    error_message TEXT
                )
                """,
                # äººè®¾è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.personas (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    name VARCHAR(100) NOT NULL,
                    persona_type VARCHAR(50) NOT NULL,
                    style VARCHAR(100),
                    target_audience VARCHAR(100),
                    characteristics TEXT,
                    tone VARCHAR(50),
                    keywords TEXT,
                    custom_prompts JSONB DEFAULT '{}',
                    is_preset BOOLEAN NOT NULL DEFAULT false,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # æç¤ºè¯æ¨¡æ¿è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.prompt_templates (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    template_key VARCHAR(255) NOT NULL UNIQUE,
                    template_content TEXT NOT NULL,
                    description TEXT,
                    category VARCHAR(50),
                    template_type VARCHAR(50),
                    template_style VARCHAR(50),
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # è„šæœ¬å†…å®¹è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.script_contents (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    task_id UUID NOT NULL REFERENCES textloom_core.tasks(id),
                    persona_id UUID REFERENCES textloom_core.personas(id),
                    script_style VARCHAR(100),
                    generation_status VARCHAR(50) NOT NULL DEFAULT 'pending',
                    titles JSONB,
                    narration JSONB,
                    material_mapping JSONB,
                    description TEXT,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # å­è§†é¢‘ä»»åŠ¡è¡¨
                """
                CREATE TABLE IF NOT EXISTS textloom_core.sub_video_tasks (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    parent_task_id UUID NOT NULL REFERENCES textloom_core.tasks(id),
                    sub_task_name VARCHAR(255) NOT NULL,
                    sub_task_type VARCHAR(50) NOT NULL,
                    status VARCHAR(50) NOT NULL DEFAULT 'pending',
                    config JSONB,
                    result JSONB,
                    created_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
                )
                """,
            ]

            for sql in sql_statements:
                await conn.execute(sql)

            logger.info("æ‰€æœ‰è¡¨åˆ›å»ºå®Œæˆ")
            return True

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"åˆ›å»ºè¡¨å¤±è´¥: {e}")
        return False


async def check_tables():
    """æ£€æŸ¥è¡¨çŠ¶æ€"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“è¡¨...")
        conn = await create_connection()
        try:
            rows = await conn.fetch(
                """
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'textloom_core' 
                ORDER BY table_name
            """
            )

            tables = [row["table_name"] for row in rows]

            if tables:
                logger.info(f"æ‰¾åˆ° {len(tables)} ä¸ªè¡¨:")
                for table in tables:
                    logger.info(f"  - {table}")
            else:
                logger.warning("textloom_core schema ä¸­æ²¡æœ‰æ‰¾åˆ°è¡¨")

            return tables
        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"æ£€æŸ¥è¡¨å¤±è´¥: {e}")
        return []


async def drop_tables():
    """åˆ é™¤æ‰€æœ‰è¡¨"""
    try:
        logger.warning("åˆ é™¤æ‰€æœ‰è¡¨...")
        conn = await create_connection()
        try:
            # æŒ‰ä¾èµ–å…³ç³»å€’åºåˆ é™¤
            tables = [
                "sub_video_tasks",
                "script_contents",
                "material_analyses",
                "media_items",
                "tasks",
                "video_projects",
                "prompt_templates",
                "personas",
            ]

            for table in tables:
                await conn.execute(
                    f"DROP TABLE IF EXISTS textloom_core.{table} CASCADE"
                )

            logger.warning("æ‰€æœ‰è¡¨å·²åˆ é™¤")
            return True

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"åˆ é™¤è¡¨å¤±è´¥: {e}")
        return False


async def verify_service():
    """éªŒè¯æœåŠ¡è¿è¡ŒçŠ¶æ€"""
    try:
        logger.info("éªŒè¯æœåŠ¡çŠ¶æ€...")
        response = requests.get("http://localhost:48095/health", timeout=5)
        if response.status_code == 200:
            logger.info("âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
            return True
        else:
            logger.warning(f"âš ï¸ æœåŠ¡å“åº”å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        logger.warning(f"âš ï¸ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        return False


async def verify_database():
    """éªŒè¯æ•°æ®åº“è¿æ¥å’Œé…ç½®"""
    try:
        logger.info("éªŒè¯æ•°æ®åº“è¿æ¥...")
        conn = await create_connection()
        try:
            version = await conn.fetchval("SELECT version()")
            logger.info(f"âœ… PostgreSQLç‰ˆæœ¬: {version[:60]}...")

            # æ£€æŸ¥schema
            schema_exists = await conn.fetchval(
                "SELECT EXISTS(SELECT 1 FROM information_schema.schemata WHERE schema_name = 'textloom_core')"
            )
            if schema_exists:
                logger.info("âœ… textloom_core schema å­˜åœ¨")
            else:
                logger.warning("âš ï¸ textloom_core schema ä¸å­˜åœ¨")

            return True
        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        return False


def get_expected_schema():
    """ä»æ¨¡å‹å®šä¹‰åŠ¨æ€è·å–é¢„æœŸschema"""
    try:
        # å¯¼å…¥æ¨¡å‹
        import os
        import sys

        sys.path.append(os.path.dirname(os.path.dirname(__file__)))

        from sqlalchemy import JSON, Boolean, DateTime, Float, Integer, String, Text
        from sqlalchemy.dialects.postgresql import UUID

        from models.db_models import Base

        schema = {}

        # éå†æ‰€æœ‰è¡¨æ¨¡å‹
        for table_name, table in Base.metadata.tables.items():
            # ç§»é™¤schemaå‰ç¼€ï¼Œåªä¿ç•™è¡¨å
            clean_table_name = (
                table_name.split(".")[-1] if "." in table_name else table_name
            )
            schema[clean_table_name] = {}

            for column in table.columns:
                col_name = column.name
                col_type = column.type

                # æ˜ å°„SQLAlchemyç±»å‹åˆ°æ•°æ®åº“ç±»å‹
                if isinstance(col_type, UUID):
                    db_type = "uuid"
                elif isinstance(col_type, String):
                    if col_type.length:
                        db_type = f"varchar({col_type.length})"
                    else:
                        db_type = "varchar"
                elif isinstance(col_type, Text):
                    db_type = "text"
                elif isinstance(col_type, Integer):
                    db_type = "integer"
                elif isinstance(col_type, Float):
                    db_type = "real"
                elif isinstance(col_type, Boolean):
                    db_type = "boolean"
                elif isinstance(col_type, DateTime):
                    db_type = "timestamp"
                elif isinstance(col_type, JSON):
                    db_type = "json"
                else:
                    db_type = str(col_type).lower()

                # è·å–é»˜è®¤å€¼
                default_value = None
                if column.default is not None:
                    if hasattr(column.default, "arg"):
                        if callable(column.default.arg):
                            default_value = (
                                "gen_random_uuid()"
                                if "uuid" in str(column.default.arg)
                                else str(column.default.arg)
                            )
                        else:
                            default_value = str(column.default.arg)
                    elif hasattr(column.default, "name"):
                        default_value = (
                            "CURRENT_TIMESTAMP"
                            if "now" in column.default.name
                            else column.default.name
                        )
                    else:
                        default_value = str(column.default)

                schema[clean_table_name][col_name] = {
                    "type": db_type,
                    "nullable": column.nullable,
                    "default": default_value,
                }

        return schema

    except Exception as e:
        logger.error(f"æ— æ³•ä»æ¨¡å‹è·å–schemaå®šä¹‰: {e}")
        logger.info("ä½¿ç”¨å¤‡ç”¨ç¡¬ç¼–ç schema...")
        # å¦‚æœåŠ¨æ€è·å–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–çš„å¤‡ç”¨å®šä¹‰
        return get_fallback_schema()


def get_fallback_schema():
    """å¤‡ç”¨çš„ç®€åŒ–schemaå®šä¹‰"""
    return {
        "video_projects": {
            "id": {"type": "uuid", "nullable": False, "default": "gen_random_uuid()"},
            "title": {"type": "varchar(255)", "nullable": False, "default": None},
            "status": {"type": "varchar(50)", "nullable": False, "default": None},
            "video_url": {"type": "text", "nullable": True, "default": None},
            "created_at": {"type": "timestamp", "nullable": False, "default": None},
            "updated_at": {"type": "timestamp", "nullable": False, "default": None},
        },
        "tasks": {
            "id": {"type": "uuid", "nullable": False, "default": "gen_random_uuid()"},
            "title": {"type": "varchar(255)", "nullable": False, "default": None},
            "description": {"type": "text", "nullable": True, "default": None},
            "creator_id": {"type": "varchar(100)", "nullable": True, "default": None},
            "task_type": {"type": "varchar(50)", "nullable": False, "default": None},
            "status": {"type": "varchar(50)", "nullable": False, "default": None},
            "progress": {"type": "integer", "nullable": False, "default": None},
            "created_at": {"type": "timestamp", "nullable": False, "default": None},
            "updated_at": {"type": "timestamp", "nullable": True, "default": None},
            "started_at": {"type": "timestamp", "nullable": True, "default": None},
            "completed_at": {"type": "timestamp", "nullable": True, "default": None},
            "error_message": {"type": "text", "nullable": True, "default": None},
            "celery_task_id": {
                "type": "varchar(255)",
                "nullable": True,
                "default": None,
            },
            "worker_name": {"type": "varchar(100)", "nullable": True, "default": None},
            "retry_count": {"type": "integer", "nullable": True, "default": None},
            "max_retries": {"type": "integer", "nullable": True, "default": None},
            "error_traceback": {"type": "text", "nullable": True, "default": None},
        },
    }


def generate_fix_sql(current_schema, expected_schema):
    """ç”Ÿæˆä¿®å¤SQLè„šæœ¬"""
    sql_statements = []
    sql_statements.append("-- TextLoom æ•°æ®åº“æ¶æ„è‡ªåŠ¨ä¿®å¤è„šæœ¬")
    sql_statements.append("-- æ ¹æ® models/db_models.py ä¸­çš„æ¨¡å‹å®šä¹‰ç”Ÿæˆ")
    sql_statements.append("")

    for table_name, expected_columns in expected_schema.items():
        current_columns = current_schema.get(table_name, {})

        sql_statements.append(f"-- =====================================")
        sql_statements.append(f"-- ä¿®å¤ {table_name} è¡¨")
        sql_statements.append(f"-- =====================================")
        sql_statements.append("")

        # æ£€æŸ¥éœ€è¦æ·»åŠ çš„å­—æ®µ
        missing_columns = []
        for col_name, col_def in expected_columns.items():
            if col_name not in current_columns:
                missing_columns.append((col_name, col_def))

        if missing_columns:
            sql_statements.append(f"-- æ·»åŠ ç¼ºå¤±çš„å­—æ®µåˆ° {table_name}")
            for col_name, col_def in missing_columns:
                col_type = col_def["type"].upper()
                nullable = "NULL" if col_def["nullable"] else "NOT NULL"
                default = f"DEFAULT {col_def['default']}" if col_def["default"] else ""

                sql_statements.append(
                    f"ALTER TABLE textloom_core.{table_name} ADD COLUMN IF NOT EXISTS {col_name} {col_type} {nullable} {default};"
                )
            sql_statements.append("")

        # æ£€æŸ¥éœ€è¦åˆ é™¤çš„å­—æ®µï¼ˆæ•°æ®åº“æœ‰ä½†æ¨¡å‹æ²¡æœ‰ï¼‰
        extra_columns = []
        for col_name in current_columns:
            if col_name not in expected_columns:
                extra_columns.append(col_name)

        if extra_columns:
            sql_statements.append(f"-- åˆ é™¤å¤šä½™çš„å­—æ®µä» {table_name}")
            for col_name in extra_columns:
                sql_statements.append(
                    f"-- ALTER TABLE textloom_core.{table_name} DROP COLUMN IF EXISTS {col_name}; -- å–æ¶ˆæ³¨é‡Šä»¥åˆ é™¤"
                )
            sql_statements.append("")

    sql_statements.append("-- è„šæœ¬ç»“æŸ")
    return "\n".join(sql_statements)


async def check_schema_diff():
    """æ£€æŸ¥æ•°æ®åº“schemaä¸æ¨¡å‹å®šä¹‰çš„å·®å¼‚"""
    try:
        logger.info("æ£€æŸ¥æ•°æ®åº“ä¸æ¨¡å‹çš„å·®å¼‚...")
        conn = await create_connection()
        try:
            # è·å–å½“å‰æ•°æ®åº“ä¸­çš„è¡¨ç»“æ„
            current_tables = {}

            # æŸ¥è¯¢æ‰€æœ‰è¡¨çš„åˆ—ä¿¡æ¯
            expected_schema = get_expected_schema()
            for table_name in expected_schema.keys():
                columns = await conn.fetch(
                    """
                    SELECT column_name, data_type, is_nullable, column_default
                    FROM information_schema.columns 
                    WHERE table_schema = 'textloom_core' AND table_name = $1
                    ORDER BY ordinal_position
                """,
                    table_name,
                )

                if columns:
                    current_tables[table_name] = {
                        row["column_name"]: {
                            "type": row["data_type"],
                            "nullable": row["is_nullable"] == "YES",
                            "default": row["column_default"],
                        }
                        for row in columns
                    }

            # å¯¹æ¯”å¹¶ç”ŸæˆæŠ¥å‘Š
            logger.info("=" * 60)
            logger.info("æ•°æ®åº“æ¶æ„å¯¹æ¯”æŠ¥å‘Š")
            logger.info("=" * 60)

            total_issues = 0
            for table_name, expected_columns in expected_schema.items():
                current_columns = current_tables.get(table_name, {})

                logger.info(f"\nğŸ“‹ {table_name} è¡¨:")
                logger.info(f"  é¢„æœŸå­—æ®µ: {len(expected_columns)} ä¸ª")
                logger.info(f"  å½“å‰å­—æ®µ: {len(current_columns)} ä¸ª")

                # æ£€æŸ¥ç¼ºå¤±å­—æ®µ
                missing = [
                    col for col in expected_columns if col not in current_columns
                ]
                if missing:
                    logger.error(
                        f"  âŒ ç¼ºå¤±å­—æ®µ ({len(missing)}): {', '.join(missing)}"
                    )
                    total_issues += len(missing)

                # æ£€æŸ¥å¤šä½™å­—æ®µ
                extra = [col for col in current_columns if col not in expected_columns]
                if extra:
                    logger.warning(f"  âš ï¸  å¤šä½™å­—æ®µ ({len(extra)}): {', '.join(extra)}")
                    total_issues += len(extra)

                if not missing and not extra:
                    logger.info(f"  âœ… å­—æ®µå®Œå…¨åŒ¹é…")

            logger.info("=" * 60)
            if total_issues > 0:
                logger.error(f"å‘ç° {total_issues} ä¸ªå­—æ®µä¸ä¸€è‡´é—®é¢˜")

                # ç”Ÿæˆä¿®å¤SQL
                fix_sql = generate_fix_sql(current_tables, expected_schema)

                # å†™å…¥æ–‡ä»¶
                with open("database_fix.sql", "w", encoding="utf-8") as f:
                    f.write(fix_sql)

                logger.info("âœ… å·²ç”Ÿæˆä¿®å¤SQLè„šæœ¬: database_fix.sql")
                logger.info("è¯·æ‰‹åŠ¨æ‰§è¡Œè¯¥è„šæœ¬ä¿®å¤æ•°æ®åº“æ¶æ„")
            else:
                logger.info("âœ… æ•°æ®åº“æ¶æ„ä¸æ¨¡å‹å®šä¹‰å®Œå…¨ä¸€è‡´")

            return current_tables

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"æ£€æŸ¥schemaå·®å¼‚å¤±è´¥: {e}")
        return {}


async def migrate_database():
    """æ‰§è¡Œæ•°æ®åº“è¿ç§» - å·²ç®€åŒ–ï¼Œè¯·ä½¿ç”¨ diff å‘½ä»¤ç”ŸæˆSQLè„šæœ¬åæ‰‹åŠ¨æ‰§è¡Œ"""
    try:
        logger.info("è¿ç§»åŠŸèƒ½å·²ç®€åŒ–...")
        logger.info("è¯·ä½¿ç”¨ä»¥ä¸‹æ­¥éª¤:")
        logger.info("1. è¿è¡Œ: python init_database.py diff")
        logger.info("2. æ£€æŸ¥ç”Ÿæˆçš„ database_fix.sql æ–‡ä»¶")
        logger.info("3. æ‰‹åŠ¨æ‰§è¡Œ SQL è„šæœ¬ä¿®å¤æ•°æ®åº“")

        # åªä¿ç•™è¿ç§»è·Ÿè¸ªè¡¨çš„åˆ›å»º
        await add_migration_tracking()

        return True

    except Exception as e:
        logger.error(f"è¿ç§»å‡†å¤‡å¤±è´¥: {e}")
        return False


async def add_migration_tracking():
    """æ·»åŠ è¿ç§»è·Ÿè¸ªè¡¨"""
    try:
        logger.info("åˆ›å»ºè¿ç§»è·Ÿè¸ªè¡¨...")
        conn = await create_connection()
        try:
            await conn.execute(
                """
                CREATE TABLE IF NOT EXISTS textloom_core.schema_migrations (
                    id SERIAL PRIMARY KEY,
                    migration_name VARCHAR(255) NOT NULL UNIQUE,
                    applied_at TIMESTAMP WITHOUT TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    description TEXT
                )
            """
            )
            logger.info("è¿ç§»è·Ÿè¸ªè¡¨åˆ›å»ºå®Œæˆ")
            return True
        finally:
            await conn.close()
    except Exception as e:
        logger.error(f"åˆ›å»ºè¿ç§»è·Ÿè¸ªè¡¨å¤±è´¥: {e}")
        return False


async def init_preset_data():
    """åˆå§‹åŒ–é¢„è®¾æ•°æ®ï¼ˆäººè®¾å’Œæç¤ºè¯æ¨¡æ¿ï¼‰"""
    try:
        logger.info("å¼€å§‹åˆå§‹åŒ–é¢„è®¾æ•°æ®...")
        conn = await create_connection()
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„è®¾äººè®¾
            existing_personas = await conn.fetch(
                """
                SELECT id FROM textloom_core.personas WHERE is_preset = true LIMIT 1
            """
            )

            if existing_personas:
                logger.info("é¢„è®¾æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
                return True

            # åˆ›å»ºé¢„è®¾äººè®¾
            preset_personas = [
                {
                    "name": "çŸ¥è¯†ç§‘æ™®åšä¸»",
                    "persona_type": "educator",
                    "style": "ä¸“ä¸šä¸¥è°¨",
                    "target_audience": "æ±‚çŸ¥è€…",
                    "characteristics": "é€»è¾‘æ¸…æ™°ï¼Œè¡¨è¾¾å‡†ç¡®ï¼Œå–„äºå°†å¤æ‚æ¦‚å¿µç®€åŒ–",
                    "tone": "ä¸“ä¸šè€Œäº²å’Œ",
                    "keywords": "çŸ¥è¯†,ç§‘æ™®,å­¦ä¹ ,æ•™è‚²",
                    "custom_prompts": {
                        "intro": "ä½œä¸ºä¸€åçŸ¥è¯†ç§‘æ™®åšä¸»ï¼Œæˆ‘è‡´åŠ›äºå°†å¤æ‚çš„çŸ¥è¯†ç”¨ç®€å•æ˜“æ‡‚çš„æ–¹å¼ä¼ è¾¾ç»™å¤§å®¶...",
                        "style": "è¯·ç”¨ä¸“ä¸šä½†é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼Œç¡®ä¿å†…å®¹å‡†ç¡®æ€§...",
                    },
                },
                {
                    "name": "ç”Ÿæ´»æ–¹å¼è¾¾äºº",
                    "persona_type": "lifestyle",
                    "style": "è½»æ¾æ„‰å¿«",
                    "target_audience": "ç”Ÿæ´»çˆ±å¥½è€…",
                    "characteristics": "çƒ­çˆ±ç”Ÿæ´»ï¼Œå–„äºåˆ†äº«å®ç”¨æŠ€å·§å’Œç¾å¥½ä½“éªŒ",
                    "tone": "äº²åˆ‡å‹å¥½",
                    "keywords": "ç”Ÿæ´»,æŠ€å·§,åˆ†äº«,ä½“éªŒ",
                    "custom_prompts": {
                        "intro": "å¤§å®¶å¥½ï¼æˆ‘æ˜¯ä½ ä»¬çš„ç”Ÿæ´»æ–¹å¼è¾¾äººï¼Œä»Šå¤©è¦å’Œå¤§å®¶åˆ†äº«...",
                        "style": "ç”¨è½»æ¾æ„‰å¿«çš„è¯­è°ƒï¼Œåˆ†äº«å®ç”¨çš„ç”Ÿæ´»æŠ€å·§...",
                    },
                },
                {
                    "name": "å•†ä¸šåˆ†æå¸ˆ",
                    "persona_type": "business",
                    "style": "æ•°æ®é©±åŠ¨",
                    "target_audience": "å•†ä¸šäººå£«",
                    "characteristics": "å–„äºæ•°æ®åˆ†æï¼Œæ´å¯Ÿå•†ä¸šè¶‹åŠ¿ï¼Œæä¾›ä¸“ä¸šè§è§£",
                    "tone": "ä¸“ä¸šæƒå¨",
                    "keywords": "å•†ä¸š,åˆ†æ,æ•°æ®,è¶‹åŠ¿",
                    "custom_prompts": {
                        "intro": "ä»å•†ä¸šåˆ†æçš„è§’åº¦æ¥çœ‹...",
                        "style": "è¯·ç”¨æ•°æ®å’Œäº‹å®æ”¯æ’‘è§‚ç‚¹ï¼Œæä¾›ä¸“ä¸šçš„å•†ä¸šåˆ†æ...",
                    },
                },
            ]

            # æ’å…¥äººè®¾æ•°æ®
            for persona in preset_personas:
                await conn.execute(
                    """
                    INSERT INTO textloom_core.personas 
                    (id, name, persona_type, style, target_audience, characteristics, tone, keywords, custom_prompts, is_preset, created_at, updated_at)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                """,
                    uuid.uuid4(),
                    persona["name"],
                    persona["persona_type"],
                    persona["style"],
                    persona["target_audience"],
                    persona["characteristics"],
                    persona["tone"],
                    persona["keywords"],
                    json.dumps(persona["custom_prompts"]),
                    True,
                    datetime.utcnow(),
                    datetime.utcnow(),
                )

            # åˆ›å»ºé¢„è®¾æç¤ºè¯æ¨¡æ¿
            preset_templates = [
                {
                    "template_key": "script_generation_base",
                    "template_content": """åŸºäºæä¾›çš„ç´ æï¼Œåˆ›å»ºä¸€ä¸ªå¼•äººå…¥èƒœçš„è§†é¢‘è„šæœ¬ã€‚

ç´ æä¿¡æ¯ï¼š
{material_info}

è¦æ±‚ï¼š
1. åˆ›å»ºå¸å¼•äººçš„æ ‡é¢˜ï¼ˆ3-5ä¸ªé€‰æ‹©ï¼‰
2. ç¼–å†™æµç•…çš„æ—ç™½å†…å®¹
3. åˆç†å®‰æ’ç´ æä½¿ç”¨é¡ºåº
4. ä¼°ç®—è§†é¢‘æ—¶é•¿
5. æ·»åŠ ç›¸å…³æ ‡ç­¾

è¯·ç¡®ä¿å†…å®¹ï¼š
- ç¬¦åˆç›®æ ‡å—ä¼—éœ€æ±‚
- é€»è¾‘æ¸…æ™°ï¼Œç»“æ„å®Œæ•´
- è¯­è¨€ç”ŸåŠ¨ï¼Œå¯Œæœ‰å¸å¼•åŠ›
- é€‚åˆè§†é¢‘åª’ä½“ç‰¹ç‚¹""",
                    "description": "åŸºç¡€è„šæœ¬ç”Ÿæˆæ¨¡æ¿",
                    "category": "script",
                },
                {
                    "template_key": "material_analysis_base",
                    "template_content": """è¯·åˆ†æè¿™ä¸ªç´ ææ–‡ä»¶ï¼š

æ–‡ä»¶ç±»å‹ï¼š{file_type}
æ–‡ä»¶ä¿¡æ¯ï¼š{file_info}

è¯·æä¾›ï¼š
1. è¯¦ç»†çš„å†…å®¹æè¿°
2. è¯†åˆ«çš„å…³é”®å¯¹è±¡/å…ƒç´ 
3. æƒ…æ„ŸåŸºè°ƒåˆ†æ
4. è§†è§‰é£æ ¼è¯„ä¼°
5. è´¨é‡è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
6. ä½¿ç”¨å»ºè®®

åˆ†æè¦å‡†ç¡®ã€å®¢è§‚ï¼Œä¸ºåç»­è„šæœ¬ç”Ÿæˆæä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚""",
                    "description": "åŸºç¡€ç´ æåˆ†ææ¨¡æ¿",
                    "category": "analysis",
                },
            ]

            # æ’å…¥æ¨¡æ¿æ•°æ®
            for template in preset_templates:
                await conn.execute(
                    """
                    INSERT INTO textloom_core.prompt_templates
                    (id, template_key, template_content, description, category, created_at)
                    VALUES ($1, $2, $3, $4, $5, $6)
                """,
                    uuid.uuid4(),
                    template["template_key"],
                    template["template_content"],
                    template["description"],
                    template["category"],
                    datetime.utcnow(),
                )

            logger.info(
                f"é¢„è®¾æ•°æ®åˆå§‹åŒ–å®Œæˆ - åˆ›å»ºäº† {len(preset_personas)} ä¸ªäººè®¾å’Œ {len(preset_templates)} ä¸ªæ¨¡æ¿"
            )
            return True

        finally:
            await conn.close()

    except Exception as e:
        logger.error(f"åˆå§‹åŒ–é¢„è®¾æ•°æ®å¤±è´¥: {e}")
        return False


async def full_verify():
    """å®Œæ•´éªŒè¯"""
    logger.info("=" * 50)
    logger.info("TextLoom ç³»ç»ŸéªŒè¯")
    logger.info("=" * 50)

    # éªŒè¯æ•°æ®åº“
    db_ok = await verify_database()

    # æ£€æŸ¥è¡¨
    tables = await check_tables()
    tables_ok = len(tables) > 0

    # éªŒè¯æœåŠ¡
    service_ok = await verify_service()

    logger.info("=" * 50)
    if db_ok and tables_ok and service_ok:
        logger.info("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
    else:
        logger.warning("âš ï¸ å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°è¾“å‡º")
    logger.info("=" * 50)


async def main():
    """ä¸»å‡½æ•°"""
    import sys

    if len(sys.argv) < 2:
        print("TextLoom æ•°æ®åº“ç®¡ç†å·¥å…·")
        print("ç”¨æ³•:")
        print("  python init_database.py create     # åˆ›å»ºschemaå’Œè¡¨")
        print("  python init_database.py check      # æ£€æŸ¥è¡¨çŠ¶æ€")
        print("  python init_database.py drop       # åˆ é™¤æ‰€æœ‰è¡¨")
        print("  python init_database.py schema     # åªåˆ›å»ºschema")
        print("  python init_database.py reset      # é‡ç½®ï¼ˆåˆ é™¤åé‡å»ºï¼‰")
        print("  python init_database.py verify     # å®Œæ•´ç³»ç»ŸéªŒè¯")
        print("  python init_database.py migrate    # æ‰§è¡Œæ•°æ®åº“è¿ç§»")
        print("  python init_database.py diff       # æ£€æŸ¥æ¨¡å‹ä¸æ•°æ®åº“å·®å¼‚")
        print("  python init_database.py init-data  # åˆå§‹åŒ–é¢„è®¾æ•°æ®ï¼ˆäººè®¾å’Œæ¨¡æ¿ï¼‰")
        return

    command = sys.argv[1].lower()

    logger.info(f"è¿æ¥æ•°æ®åº“: {settings.database_url.split('@')[1]}")

    try:
        if command == "create":
            await create_schema()
            success = await create_tables()
            if success:
                await check_tables()

        elif command == "check":
            await check_tables()

        elif command == "drop":
            confirm = input("ç¡®è®¤åˆ é™¤æ‰€æœ‰è¡¨? (yes/no): ")
            if confirm.lower() == "yes":
                await drop_tables()
            else:
                logger.info("æ“ä½œå·²å–æ¶ˆ")

        elif command == "schema":
            await create_schema()

        elif command == "reset":
            confirm = input("ç¡®è®¤é‡ç½®æ•°æ®åº“? (yes/no): ")
            if confirm.lower() == "yes":
                await drop_tables()
                await create_schema()
                await create_tables()
                await check_tables()
            else:
                logger.info("æ“ä½œå·²å–æ¶ˆ")

        elif command == "verify":
            await full_verify()

        elif command == "diff":
            await check_schema_diff()

        elif command == "migrate":
            await add_migration_tracking()
            await migrate_database()

        elif command == "init-data":
            success = await init_preset_data()
            if success:
                logger.info("âœ… é¢„è®¾æ•°æ®åˆå§‹åŒ–å®Œæˆ")
            else:
                logger.error("âŒ é¢„è®¾æ•°æ®åˆå§‹åŒ–å¤±è´¥")

        else:
            logger.error(f"æœªçŸ¥å‘½ä»¤: {command}")

    except Exception as e:
        logger.error(f"æ“ä½œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
